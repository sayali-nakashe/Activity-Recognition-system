{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Recognition system based on Multisensor data fusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project , I have studied various methods for classification of data on the time series dataset.  <br>\n",
    "\n",
    "The methods are listed below: <br>\n",
    "1) Binary Classifiation using Logistic Regression  <br>\n",
    "2) Binary Classifiation using L-1 penalized Logistic Regression  <br>\n",
    "3) Multi-class Classifiation using Multinomial Logistic Regression  <br>\n",
    "4) Multi-class Classifiation using Multinomial Naive Bayes  <br>\n",
    "5) Multi-class Classifiation using Gaussian Naive Bayes  <br>\n",
    "\n",
    "In this problem, we classify the activities of humans based on time series obtained by a Wireless Sensor Network. \n",
    "The dataset contains 7 folders that represent seven types of activities. In each folder, there are multiple files each of which represents an instant of a human performing an activity. Each file containis 6 time series collected from activities of the same person, which are called avg rss12, var rss12, avg rss13, var rss13, vg rss23, and ar rss23. There are 88 instances in the dataset, each of which contains 6 time series and each time series has 480 consecutive values.\n",
    "\n",
    "The data is downloaded from : https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\%29\n",
    "\n",
    "Feature engineering and Extraction is used in this project and the various machine learning models are analysed and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Extraction of time-domain features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In time-series classification the time-domain features used are-\n",
    "</br>\n",
    "1. Maximum value </br>\n",
    "2. Co-efficient of Skewness </br>\n",
    "3. Range </br>\n",
    "4. Inter-quartile range </br>\n",
    "5. Peaks in a time series </br>\n",
    "6. Median </br>\n",
    "7. 10th percentile </br>\n",
    "8. Mean value </br>\n",
    "9. Minimum value </br>\n",
    "10. Kurtosis </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series in each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities=[\"bending1\",\"bending2\",\"cycling\",\"lying\",\"sitting\",\"standing\",\"walking\"]\n",
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "extract=[\"min\",\"max\",\"mean\",\"median\",\"std_dev\",\"first_quar\",\"third_quar\"]\n",
    "table_index=[]\n",
    "for f in features:\n",
    "    for p in range(len(extract)):\n",
    "        table_index.append((extract[p]+\"_\"+f))\n",
    "#table_index.append('activity')\n",
    "table_frame=pd.DataFrame(columns=table_index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the time domain features for all 6 time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   min_avg_rss12  max_avg_rss12  mean_avg_rss12  median_avg_rss12  \\\n",
      "0          37.25          45.00       40.624792             40.50   \n",
      "1          38.00          45.67       42.812812             42.50   \n",
      "2          35.00          47.40       43.954500             44.33   \n",
      "3          33.00          47.75       42.179813             43.50   \n",
      "4          33.00          45.75       41.678063             41.75   \n",
      "\n",
      "   std_dev_avg_rss12  first_quar_avg_rss12  third_quar_avg_rss12  \\\n",
      "0           1.476967                 39.25                 42.00   \n",
      "1           1.435550                 42.00                 43.67   \n",
      "2           1.558835                 43.00                 45.00   \n",
      "3           3.670666                 39.15                 45.00   \n",
      "4           2.243490                 41.33                 42.75   \n",
      "\n",
      "   min_var_rss12  max_var_rss12  mean_var_rss12          ...           \\\n",
      "0            0.0           1.30        0.358604          ...            \n",
      "1            0.0           1.22        0.372438          ...            \n",
      "2            0.0           1.70        0.426250          ...            \n",
      "3            0.0           3.00        0.696042          ...            \n",
      "4            0.0           2.83        0.535979          ...            \n",
      "\n",
      "   std_dev_avg_rss23  first_quar_avg_rss23  third_quar_avg_rss23  \\\n",
      "0           2.188449               33.0000                 36.00   \n",
      "1           1.995255               32.0000                 34.50   \n",
      "2           1.999604               35.3625                 36.50   \n",
      "3           3.849448               30.4575                 36.33   \n",
      "4           2.411026               28.4575                 31.25   \n",
      "\n",
      "   min_var_rss23  max_var_rss23  mean_var_rss23  median_var_rss23  \\\n",
      "0            0.0           1.92        0.570583              0.43   \n",
      "1            0.0           3.11        0.571083              0.43   \n",
      "2            0.0           1.79        0.493292              0.43   \n",
      "3            0.0           2.18        0.613521              0.50   \n",
      "4            0.0           1.79        0.383292              0.43   \n",
      "\n",
      "   std_dev_var_rss23  first_quar_var_rss23  third_quar_var_rss23  \n",
      "0           0.582915                   0.0                  1.30  \n",
      "1           0.601010                   0.0                  1.30  \n",
      "2           0.513506                   0.0                  0.94  \n",
      "3           0.524317                   0.0                  1.00  \n",
      "4           0.389164                   0.0                  0.50  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "new_list=[]\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM/{0}\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4,usecols=range(1,7))\n",
    "        ext=[]\n",
    "        ext1=[]\n",
    "        for f in features:\n",
    "            ext.append(np.min(df[f]))\n",
    "            ext.append(np.max(df[f]))\n",
    "            ext.append(np.mean(df[f]))\n",
    "            ext.append(np.median(df[f]))\n",
    "            ext.append(df[f].std())\n",
    "            ext.append(df[f].quantile(0.25))\n",
    "            ext.append(df[f].quantile(0.75))\n",
    "        #ext.append(activity)\n",
    "        new_list.append(ext)\n",
    "        \n",
    "new_dataset=pd.DataFrame(new_list,columns=table_index)\n",
    "print(new_dataset.head())\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the standard deviation of each of the time-domain features extracted from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min_avg_rss12</th>\n",
       "      <td>9.569975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss12</th>\n",
       "      <td>4.394362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss12</th>\n",
       "      <td>5.335718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss12</th>\n",
       "      <td>5.440054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss12</th>\n",
       "      <td>1.772153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss12</th>\n",
       "      <td>6.153590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss12</th>\n",
       "      <td>5.138925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss12</th>\n",
       "      <td>5.062729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss12</th>\n",
       "      <td>1.574164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss12</th>\n",
       "      <td>1.412244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss12</th>\n",
       "      <td>0.884105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss12</th>\n",
       "      <td>0.946386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss12</th>\n",
       "      <td>2.125266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_avg_rss13</th>\n",
       "      <td>2.956462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss13</th>\n",
       "      <td>4.875137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss13</th>\n",
       "      <td>4.008380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss13</th>\n",
       "      <td>4.036396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss13</th>\n",
       "      <td>0.946710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss13</th>\n",
       "      <td>4.220658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss13</th>\n",
       "      <td>4.171628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss13</th>\n",
       "      <td>2.183625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss13</th>\n",
       "      <td>1.166114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss13</th>\n",
       "      <td>1.145586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss13</th>\n",
       "      <td>0.458242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss13</th>\n",
       "      <td>0.843620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss13</th>\n",
       "      <td>1.552504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_avg_rss23</th>\n",
       "      <td>6.124001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss23</th>\n",
       "      <td>5.741238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss23</th>\n",
       "      <td>5.675593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss23</th>\n",
       "      <td>5.813782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss23</th>\n",
       "      <td>1.024898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss23</th>\n",
       "      <td>6.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss23</th>\n",
       "      <td>5.531720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss23</th>\n",
       "      <td>0.045838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss23</th>\n",
       "      <td>2.518921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss23</th>\n",
       "      <td>1.154812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss23</th>\n",
       "      <td>1.086474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss23</th>\n",
       "      <td>0.517617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss23</th>\n",
       "      <td>0.758584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss23</th>\n",
       "      <td>1.523599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           std\n",
       "min_avg_rss12         9.569975\n",
       "max_avg_rss12         4.394362\n",
       "mean_avg_rss12        5.335718\n",
       "median_avg_rss12      5.440054\n",
       "std_dev_avg_rss12     1.772153\n",
       "first_quar_avg_rss12  6.153590\n",
       "third_quar_avg_rss12  5.138925\n",
       "min_var_rss12         0.000000\n",
       "max_var_rss12         5.062729\n",
       "mean_var_rss12        1.574164\n",
       "median_var_rss12      1.412244\n",
       "std_dev_var_rss12     0.884105\n",
       "first_quar_var_rss12  0.946386\n",
       "third_quar_var_rss12  2.125266\n",
       "min_avg_rss13         2.956462\n",
       "max_avg_rss13         4.875137\n",
       "mean_avg_rss13        4.008380\n",
       "median_avg_rss13      4.036396\n",
       "std_dev_avg_rss13     0.946710\n",
       "first_quar_avg_rss13  4.220658\n",
       "third_quar_avg_rss13  4.171628\n",
       "min_var_rss13         0.000000\n",
       "max_var_rss13         2.183625\n",
       "mean_var_rss13        1.166114\n",
       "median_var_rss13      1.145586\n",
       "std_dev_var_rss13     0.458242\n",
       "first_quar_var_rss13  0.843620\n",
       "third_quar_var_rss13  1.552504\n",
       "min_avg_rss23         6.124001\n",
       "max_avg_rss23         5.741238\n",
       "mean_avg_rss23        5.675593\n",
       "median_avg_rss23      5.813782\n",
       "std_dev_avg_rss23     1.024898\n",
       "first_quar_avg_rss23  6.096465\n",
       "third_quar_avg_rss23  5.531720\n",
       "min_var_rss23         0.045838\n",
       "max_var_rss23         2.518921\n",
       "mean_var_rss23        1.154812\n",
       "median_var_rss23      1.086474\n",
       "std_dev_var_rss23     0.517617\n",
       "first_quar_var_rss23  0.758584\n",
       "third_quar_var_rss23  1.523599"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "std_deviation= new_dataset.describe()[new_dataset.describe().index == 'std']\n",
    "std_deviation=std_deviation.T\n",
    "\n",
    "std_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, using Python’s bootstrapped method to build a 90% bootstrap confidence interval for the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower={}\n",
    "upper={}\n",
    "from sklearn.utils import resample\n",
    "for i in new_dataset.columns.tolist():\n",
    "    bootstrap = []\n",
    "    for p in range(n_iterations):\n",
    "        sample = resample(new_dataset[i])\n",
    "        bootstrap.append(np.std(sample))\n",
    "    bootstrap.sort()\n",
    "    lower[i]=bootstrap[49]  \n",
    "    upper[i]=bootstrap[949]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>Confidence lower bound</th>\n",
       "      <th>Confidence upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min_avg_rss12</th>\n",
       "      <td>9.569975</td>\n",
       "      <td>8.276315</td>\n",
       "      <td>10.809425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss12</th>\n",
       "      <td>4.394362</td>\n",
       "      <td>3.264599</td>\n",
       "      <td>5.281532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss12</th>\n",
       "      <td>5.335718</td>\n",
       "      <td>4.661433</td>\n",
       "      <td>5.865653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss12</th>\n",
       "      <td>5.440054</td>\n",
       "      <td>4.722125</td>\n",
       "      <td>5.942180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss12</th>\n",
       "      <td>1.772153</td>\n",
       "      <td>1.565369</td>\n",
       "      <td>1.932216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss12</th>\n",
       "      <td>6.153590</td>\n",
       "      <td>5.518130</td>\n",
       "      <td>6.617273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss12</th>\n",
       "      <td>5.138925</td>\n",
       "      <td>4.292295</td>\n",
       "      <td>5.756055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss12</th>\n",
       "      <td>5.062729</td>\n",
       "      <td>4.588949</td>\n",
       "      <td>5.394194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss12</th>\n",
       "      <td>1.574164</td>\n",
       "      <td>1.388562</td>\n",
       "      <td>1.692568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss12</th>\n",
       "      <td>1.412244</td>\n",
       "      <td>1.228745</td>\n",
       "      <td>1.526328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss12</th>\n",
       "      <td>0.884105</td>\n",
       "      <td>0.799776</td>\n",
       "      <td>0.934676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss12</th>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.822006</td>\n",
       "      <td>1.036684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss12</th>\n",
       "      <td>2.125266</td>\n",
       "      <td>1.895714</td>\n",
       "      <td>2.278168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_avg_rss13</th>\n",
       "      <td>2.956462</td>\n",
       "      <td>2.737506</td>\n",
       "      <td>3.098685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss13</th>\n",
       "      <td>4.875137</td>\n",
       "      <td>4.144494</td>\n",
       "      <td>5.472938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss13</th>\n",
       "      <td>4.008380</td>\n",
       "      <td>3.410062</td>\n",
       "      <td>4.451059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss13</th>\n",
       "      <td>4.036396</td>\n",
       "      <td>3.460683</td>\n",
       "      <td>4.533077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss13</th>\n",
       "      <td>0.946710</td>\n",
       "      <td>0.759189</td>\n",
       "      <td>1.122237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss13</th>\n",
       "      <td>4.220658</td>\n",
       "      <td>3.646836</td>\n",
       "      <td>4.684975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss13</th>\n",
       "      <td>4.171628</td>\n",
       "      <td>3.527040</td>\n",
       "      <td>4.681682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss13</th>\n",
       "      <td>2.183625</td>\n",
       "      <td>1.953260</td>\n",
       "      <td>2.347756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss13</th>\n",
       "      <td>1.166114</td>\n",
       "      <td>1.076998</td>\n",
       "      <td>1.216319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss13</th>\n",
       "      <td>1.145586</td>\n",
       "      <td>1.034513</td>\n",
       "      <td>1.198027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss13</th>\n",
       "      <td>0.458242</td>\n",
       "      <td>0.417010</td>\n",
       "      <td>0.482986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss13</th>\n",
       "      <td>0.843620</td>\n",
       "      <td>0.767229</td>\n",
       "      <td>0.885532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss13</th>\n",
       "      <td>1.552504</td>\n",
       "      <td>1.424047</td>\n",
       "      <td>1.622372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_avg_rss23</th>\n",
       "      <td>6.124001</td>\n",
       "      <td>4.390592</td>\n",
       "      <td>7.409025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_avg_rss23</th>\n",
       "      <td>5.741238</td>\n",
       "      <td>4.732085</td>\n",
       "      <td>6.487930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_avg_rss23</th>\n",
       "      <td>5.675593</td>\n",
       "      <td>4.451081</td>\n",
       "      <td>6.652587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_avg_rss23</th>\n",
       "      <td>5.813782</td>\n",
       "      <td>4.546775</td>\n",
       "      <td>6.868577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_avg_rss23</th>\n",
       "      <td>1.024898</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>1.225545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_avg_rss23</th>\n",
       "      <td>6.096465</td>\n",
       "      <td>4.739583</td>\n",
       "      <td>7.094928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_avg_rss23</th>\n",
       "      <td>5.531720</td>\n",
       "      <td>4.343517</td>\n",
       "      <td>6.522883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_var_rss23</th>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_var_rss23</th>\n",
       "      <td>2.518921</td>\n",
       "      <td>2.249822</td>\n",
       "      <td>2.744433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_var_rss23</th>\n",
       "      <td>1.154812</td>\n",
       "      <td>1.056140</td>\n",
       "      <td>1.206960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_var_rss23</th>\n",
       "      <td>1.086474</td>\n",
       "      <td>0.990353</td>\n",
       "      <td>1.141614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev_var_rss23</th>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.475519</td>\n",
       "      <td>0.543060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quar_var_rss23</th>\n",
       "      <td>0.758584</td>\n",
       "      <td>0.686195</td>\n",
       "      <td>0.802222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quar_var_rss23</th>\n",
       "      <td>1.523599</td>\n",
       "      <td>1.378228</td>\n",
       "      <td>1.590020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           std  Confidence lower bound  Confidence upper bound\n",
       "min_avg_rss12         9.569975                8.276315               10.809425\n",
       "max_avg_rss12         4.394362                3.264599                5.281532\n",
       "mean_avg_rss12        5.335718                4.661433                5.865653\n",
       "median_avg_rss12      5.440054                4.722125                5.942180\n",
       "std_dev_avg_rss12     1.772153                1.565369                1.932216\n",
       "first_quar_avg_rss12  6.153590                5.518130                6.617273\n",
       "third_quar_avg_rss12  5.138925                4.292295                5.756055\n",
       "min_var_rss12         0.000000                0.000000                0.000000\n",
       "max_var_rss12         5.062729                4.588949                5.394194\n",
       "mean_var_rss12        1.574164                1.388562                1.692568\n",
       "median_var_rss12      1.412244                1.228745                1.526328\n",
       "std_dev_var_rss12     0.884105                0.799776                0.934676\n",
       "first_quar_var_rss12  0.946386                0.822006                1.036684\n",
       "third_quar_var_rss12  2.125266                1.895714                2.278168\n",
       "min_avg_rss13         2.956462                2.737506                3.098685\n",
       "max_avg_rss13         4.875137                4.144494                5.472938\n",
       "mean_avg_rss13        4.008380                3.410062                4.451059\n",
       "median_avg_rss13      4.036396                3.460683                4.533077\n",
       "std_dev_avg_rss13     0.946710                0.759189                1.122237\n",
       "first_quar_avg_rss13  4.220658                3.646836                4.684975\n",
       "third_quar_avg_rss13  4.171628                3.527040                4.681682\n",
       "min_var_rss13         0.000000                0.000000                0.000000\n",
       "max_var_rss13         2.183625                1.953260                2.347756\n",
       "mean_var_rss13        1.166114                1.076998                1.216319\n",
       "median_var_rss13      1.145586                1.034513                1.198027\n",
       "std_dev_var_rss13     0.458242                0.417010                0.482986\n",
       "first_quar_var_rss13  0.843620                0.767229                0.885532\n",
       "third_quar_var_rss13  1.552504                1.424047                1.622372\n",
       "min_avg_rss23         6.124001                4.390592                7.409025\n",
       "max_avg_rss23         5.741238                4.732085                6.487930\n",
       "mean_avg_rss23        5.675593                4.451081                6.652587\n",
       "median_avg_rss23      5.813782                4.546775                6.868577\n",
       "std_dev_avg_rss23     1.024898                0.799864                1.225545\n",
       "first_quar_avg_rss23  6.096465                4.739583                7.094928\n",
       "third_quar_avg_rss23  5.531720                4.343517                6.522883\n",
       "min_var_rss23         0.045838                0.000000                0.078029\n",
       "max_var_rss23         2.518921                2.249822                2.744433\n",
       "mean_var_rss23        1.154812                1.056140                1.206960\n",
       "median_var_rss23      1.086474                0.990353                1.141614\n",
       "std_dev_var_rss23     0.517617                0.475519                0.543060\n",
       "first_quar_var_rss23  0.758584                0.686195                0.802222\n",
       "third_quar_var_rss23  1.523599                1.378228                1.590020"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prin\n",
    "std_deviation[\"Confidence lower bound\"]=pd.Series(lower)\n",
    "std_deviation[\"Confidence upper bound\"]=pd.Series(upper)\n",
    "std_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the three most important time-domain features :\n",
    "#### Median: For data which is not much changing across the column, median is a good feature for getting central tendency\n",
    "#### Mean : It gives the average value of the time-series\n",
    "#### Max: It gives the peak values of the time series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Using Logistic Regression\n",
    "#### Classifying to Activities to Bending and Non-Bending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_activity_index=table_index\n",
    "table_activity_index.append('activity')\n",
    "new_list=[]\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4,usecols=range(1,7))\n",
    "        ext=[]\n",
    "        ext1=[]\n",
    "        for f in features:\n",
    "            ext.append(np.min(df[f]))\n",
    "            ext.append(np.max(df[f]))\n",
    "            ext.append(np.mean(df[f]))\n",
    "            ext.append(np.median(df[f]))\n",
    "            ext.append(df[f].std())\n",
    "            ext.append(df[f].quantile(0.25))\n",
    "            ext.append(df[f].quantile(0.75))\n",
    "        ext.append(activity)\n",
    "        new_list.append(ext)\n",
    "        \n",
    "train_set=pd.DataFrame(new_list,columns=table_index)\n",
    "#train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_avg_rss12</th>\n",
       "      <th>max_avg_rss12</th>\n",
       "      <th>mean_avg_rss12</th>\n",
       "      <th>median_avg_rss12</th>\n",
       "      <th>std_dev_avg_rss12</th>\n",
       "      <th>first_quar_avg_rss12</th>\n",
       "      <th>third_quar_avg_rss12</th>\n",
       "      <th>min_var_rss12</th>\n",
       "      <th>max_var_rss12</th>\n",
       "      <th>mean_var_rss12</th>\n",
       "      <th>...</th>\n",
       "      <th>first_quar_avg_rss23</th>\n",
       "      <th>third_quar_avg_rss23</th>\n",
       "      <th>min_var_rss23</th>\n",
       "      <th>max_var_rss23</th>\n",
       "      <th>mean_var_rss23</th>\n",
       "      <th>median_var_rss23</th>\n",
       "      <th>std_dev_var_rss23</th>\n",
       "      <th>first_quar_var_rss23</th>\n",
       "      <th>third_quar_var_rss23</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.2500</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.500</td>\n",
       "      <td>1.435550</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.75</td>\n",
       "      <td>51.00</td>\n",
       "      <td>24.562958</td>\n",
       "      <td>24.250</td>\n",
       "      <td>3.737514</td>\n",
       "      <td>23.1875</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.590833</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.693720</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.870</td>\n",
       "      <td>bending2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>42.75</td>\n",
       "      <td>27.464604</td>\n",
       "      <td>28.000</td>\n",
       "      <td>3.583582</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.449708</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>20.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.76</td>\n",
       "      <td>1.122125</td>\n",
       "      <td>0.830</td>\n",
       "      <td>1.012342</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>1.300</td>\n",
       "      <td>bending2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>37.177042</td>\n",
       "      <td>36.250</td>\n",
       "      <td>3.581301</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>40.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.58</td>\n",
       "      <td>2.374208</td>\n",
       "      <td>...</td>\n",
       "      <td>17.9500</td>\n",
       "      <td>21.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2.921729</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.852600</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.75</td>\n",
       "      <td>44.75</td>\n",
       "      <td>37.561188</td>\n",
       "      <td>36.875</td>\n",
       "      <td>3.226507</td>\n",
       "      <td>35.2500</td>\n",
       "      <td>40.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.91</td>\n",
       "      <td>2.080688</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>2.765896</td>\n",
       "      <td>2.450</td>\n",
       "      <td>1.769203</td>\n",
       "      <td>1.4100</td>\n",
       "      <td>3.770</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.00</td>\n",
       "      <td>44.67</td>\n",
       "      <td>37.058708</td>\n",
       "      <td>36.000</td>\n",
       "      <td>3.710180</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>40.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.17</td>\n",
       "      <td>2.438146</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.55</td>\n",
       "      <td>2.983750</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.815730</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>4.150</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.50</td>\n",
       "      <td>30.00</td>\n",
       "      <td>27.716375</td>\n",
       "      <td>27.500</td>\n",
       "      <td>1.442253</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.363688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5000</td>\n",
       "      <td>10.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.613688</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.75</td>\n",
       "      <td>48.33</td>\n",
       "      <td>44.182937</td>\n",
       "      <td>48.000</td>\n",
       "      <td>7.495615</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.101875</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.5425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.692771</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.3225</td>\n",
       "      <td>0.940</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.00</td>\n",
       "      <td>48.25</td>\n",
       "      <td>48.004167</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6700</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.641229</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.388372</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.830</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>42.363563</td>\n",
       "      <td>43.000</td>\n",
       "      <td>2.068247</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>43.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.492563</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1875</td>\n",
       "      <td>17.6900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.034021</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.985627</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>1.250</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.00</td>\n",
       "      <td>50.75</td>\n",
       "      <td>45.917667</td>\n",
       "      <td>45.635</td>\n",
       "      <td>1.089027</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>46.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.324542</td>\n",
       "      <td>...</td>\n",
       "      <td>16.5000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.904604</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.896171</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.120</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44.50</td>\n",
       "      <td>46.75</td>\n",
       "      <td>45.239667</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.429915</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>45.3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6275</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.837250</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.835344</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.120</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33.33</td>\n",
       "      <td>48.00</td>\n",
       "      <td>44.334729</td>\n",
       "      <td>45.000</td>\n",
       "      <td>2.476940</td>\n",
       "      <td>42.2500</td>\n",
       "      <td>46.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.432958</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3300</td>\n",
       "      <td>17.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.673609</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>1.250</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>43.174938</td>\n",
       "      <td>43.670</td>\n",
       "      <td>1.989052</td>\n",
       "      <td>42.5000</td>\n",
       "      <td>44.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>...</td>\n",
       "      <td>12.7500</td>\n",
       "      <td>16.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.911979</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.666161</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>1.220</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32.75</td>\n",
       "      <td>47.00</td>\n",
       "      <td>42.760563</td>\n",
       "      <td>44.500</td>\n",
       "      <td>3.398919</td>\n",
       "      <td>41.3300</td>\n",
       "      <td>45.3725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.486167</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>18.5650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.842271</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.722165</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.090</td>\n",
       "      <td>standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19.33</td>\n",
       "      <td>43.50</td>\n",
       "      <td>34.227771</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.889576</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>37.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>3.995729</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7500</td>\n",
       "      <td>18.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>3.394125</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.792090</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>4.425</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>33.509729</td>\n",
       "      <td>34.125</td>\n",
       "      <td>4.850923</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.05</td>\n",
       "      <td>4.450771</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6275</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>3.378479</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.787360</td>\n",
       "      <td>2.0600</td>\n",
       "      <td>4.440</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.00</td>\n",
       "      <td>46.75</td>\n",
       "      <td>34.660583</td>\n",
       "      <td>35.000</td>\n",
       "      <td>5.315110</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>4.200896</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>3.244396</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.630983</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.240</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_avg_rss12  max_avg_rss12  mean_avg_rss12  median_avg_rss12  \\\n",
       "0           37.25          45.00       40.624792            40.500   \n",
       "1           38.00          45.67       42.812812            42.500   \n",
       "2           12.75          51.00       24.562958            24.250   \n",
       "3            0.00          42.75       27.464604            28.000   \n",
       "4           24.25          45.00       37.177042            36.250   \n",
       "5           28.75          44.75       37.561188            36.875   \n",
       "6           22.00          44.67       37.058708            36.000   \n",
       "7           23.50          30.00       27.716375            27.500   \n",
       "8           24.75          48.33       44.182937            48.000   \n",
       "9           48.00          48.25       48.004167            48.000   \n",
       "10          33.25          48.00       42.363563            43.000   \n",
       "11          37.00          50.75       45.917667            45.635   \n",
       "12          44.50          46.75       45.239667            45.000   \n",
       "13          33.33          48.00       44.334729            45.000   \n",
       "14          35.50          46.25       43.174938            43.670   \n",
       "15          32.75          47.00       42.760563            44.500   \n",
       "16          19.33          43.50       34.227771            35.500   \n",
       "17          12.50          45.00       33.509729            34.125   \n",
       "18          15.00          46.75       34.660583            35.000   \n",
       "\n",
       "    std_dev_avg_rss12  first_quar_avg_rss12  third_quar_avg_rss12  \\\n",
       "0            1.476967               39.2500               42.0000   \n",
       "1            1.435550               42.0000               43.6700   \n",
       "2            3.737514               23.1875               26.5000   \n",
       "3            3.583582               25.5000               30.0000   \n",
       "4            3.581301               34.5000               40.2500   \n",
       "5            3.226507               35.2500               40.2500   \n",
       "6            3.710180               34.5000               40.0625   \n",
       "7            1.442253               27.0000               29.0000   \n",
       "8            7.495615               48.0000               48.0000   \n",
       "9            0.032038               48.0000               48.0000   \n",
       "10           2.068247               42.0000               43.5000   \n",
       "11           1.089027               45.0000               46.5000   \n",
       "12           0.429915               45.0000               45.3300   \n",
       "13           2.476940               42.2500               46.5000   \n",
       "14           1.989052               42.5000               44.5000   \n",
       "15           3.398919               41.3300               45.3725   \n",
       "16           4.889576               30.5000               37.7500   \n",
       "17           4.850923               30.5000               36.7500   \n",
       "18           5.315110               31.0000               38.2500   \n",
       "\n",
       "    min_var_rss12  max_var_rss12  mean_var_rss12    ...     \\\n",
       "0             0.0           1.30        0.358604    ...      \n",
       "1             0.0           1.22        0.372438    ...      \n",
       "2             0.0           6.87        0.590833    ...      \n",
       "3             0.0           7.76        0.449708    ...      \n",
       "4             0.0           8.58        2.374208    ...      \n",
       "5             0.0           9.91        2.080688    ...      \n",
       "6             0.0          14.17        2.438146    ...      \n",
       "7             0.0           1.79        0.363688    ...      \n",
       "8             0.0           3.11        0.101875    ...      \n",
       "9             0.0           0.43        0.007167    ...      \n",
       "10            0.0           4.44        0.492563    ...      \n",
       "11            0.0           4.87        0.324542    ...      \n",
       "12            0.0           1.00        0.172958    ...      \n",
       "13            0.0           3.90        0.432958    ...      \n",
       "14            0.0           2.12        0.506583    ...      \n",
       "15            0.0           3.34        0.486167    ...      \n",
       "16            0.0          14.50        3.995729    ...      \n",
       "17            0.0          13.05        4.450771    ...      \n",
       "18            0.0          13.44        4.200896    ...      \n",
       "\n",
       "    first_quar_avg_rss23  third_quar_avg_rss23  min_var_rss23  max_var_rss23  \\\n",
       "0                33.0000               36.0000            0.0           1.92   \n",
       "1                32.0000               34.5000            0.0           3.11   \n",
       "2                20.5000               27.0000            0.0           4.97   \n",
       "3                15.0000               20.7500            0.0           6.76   \n",
       "4                17.9500               21.7500            0.0           9.34   \n",
       "5                18.0000               21.5000            0.0           9.62   \n",
       "6                16.0000               21.0000            0.0           8.55   \n",
       "7                 5.5000               10.7500            0.0           4.50   \n",
       "8                 2.0000                5.5425            0.0           3.91   \n",
       "9                 4.6700               10.0000            0.0           2.50   \n",
       "10               10.1875               17.6900            0.0           6.02   \n",
       "11               16.5000               21.0000            0.0           7.22   \n",
       "12               17.6275               21.0000            0.0           8.20   \n",
       "13                9.3300               17.7500            0.0           5.02   \n",
       "14               12.7500               16.5000            0.0           5.72   \n",
       "15               13.0000               18.5650            0.0           5.73   \n",
       "16               14.7500               18.6700            0.0           9.74   \n",
       "17               14.6275               18.7500            0.0           8.96   \n",
       "18               14.2500               18.5000            0.0           8.99   \n",
       "\n",
       "    mean_var_rss23  median_var_rss23  std_dev_var_rss23  first_quar_var_rss23  \\\n",
       "0         0.570583             0.430           0.582915                0.0000   \n",
       "1         0.571083             0.430           0.601010                0.0000   \n",
       "2         0.700188             0.500           0.693720                0.4300   \n",
       "3         1.122125             0.830           1.012342                0.4700   \n",
       "4         2.921729             2.500           1.852600                1.5000   \n",
       "5         2.765896             2.450           1.769203                1.4100   \n",
       "6         2.983750             2.570           1.815730                1.5000   \n",
       "7         0.734271             0.710           0.613688                0.4300   \n",
       "8         0.692771             0.500           0.675781                0.3225   \n",
       "9         0.641229             0.500           0.388372                0.4600   \n",
       "10        1.034021             0.830           0.985627                0.4700   \n",
       "11        0.904604             0.710           0.896171                0.4300   \n",
       "12        0.837250             0.710           0.835344                0.4300   \n",
       "13        0.933000             0.830           0.673609                0.4700   \n",
       "14        0.911979             0.830           0.666161                0.4700   \n",
       "15        0.842271             0.710           0.722165                0.4300   \n",
       "16        3.394125             3.100           1.792090                2.1050   \n",
       "17        3.378479             3.085           1.787360                2.0600   \n",
       "18        3.244396             3.000           1.630983                2.1200   \n",
       "\n",
       "    third_quar_var_rss23  activity  \n",
       "0                  1.300  bending1  \n",
       "1                  1.300  bending1  \n",
       "2                  0.870  bending2  \n",
       "3                  1.300  bending2  \n",
       "4                  3.900   cycling  \n",
       "5                  3.770   cycling  \n",
       "6                  4.150   cycling  \n",
       "7                  1.000     lying  \n",
       "8                  0.940     lying  \n",
       "9                  0.830     lying  \n",
       "10                 1.250   sitting  \n",
       "11                 1.120   sitting  \n",
       "12                 1.120   sitting  \n",
       "13                 1.250  standing  \n",
       "14                 1.220  standing  \n",
       "15                 1.090  standing  \n",
       "16                 4.425   walking  \n",
       "17                 4.440   walking  \n",
       "18                 4.240   walking  \n",
       "\n",
       "[19 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list=[]\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/test\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4,usecols=range(1,7))\n",
    "        ext=[]\n",
    "        for f in features:\n",
    "            ext.append(np.min(df[f]))\n",
    "            ext.append(np.max(df[f]))\n",
    "            ext.append(np.mean(df[f]))\n",
    "            ext.append(np.median(df[f]))\n",
    "            ext.append(df[f].std())\n",
    "            ext.append(df[f].quantile(0.25))\n",
    "            ext.append(df[f].quantile(0.75))\n",
    "        ext.append(activity)\n",
    "        new_list.append(ext)\n",
    "        \n",
    "test_set=pd.DataFrame(new_list,columns=table_index)\n",
    "#test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.activity.replace(['bending1', 'bending2',\"cycling\",\"lying\",\"sitting\",\"standing\",\"walking\"], ['bending','bending','non-bending','non-bending','non-bending','non-bending','non-bending'], inplace=True)\n",
    "\n",
    "test_set.activity.replace(['bending1', 'bending2',\"cycling\",\"lying\",\"sitting\",\"standing\",\"walking\"], ['bending','bending','non-bending','non-bending','non-bending','non-bending','non-bending'], inplace=True)\n",
    "#train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_avg_rss12',\n",
       " 'mean_avg_rss12',\n",
       " 'median_avg_rss12',\n",
       " 'max_var_rss12',\n",
       " 'mean_var_rss12',\n",
       " 'median_var_rss12',\n",
       " 'max_var_rss23',\n",
       " 'mean_var_rss23',\n",
       " 'median_var_rss23',\n",
       " 'activity']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_columns1 = [col for col in train_set.columns.tolist() if col.endswith('avg_rss12') or col.endswith('var_rss12') or col.endswith('var_rss23') or col == 'activity']\n",
    "train_subset=train_set[train_subset_columns1]\n",
    "train_subset_columns2= [col for col in train_subset.columns.tolist() if col.startswith('max') or col.startswith('mean') or col.startswith('median') or col == 'activity']\n",
    "train_subset=train_subset[train_subset_columns2]\n",
    "#train_subset.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ScatterPlots to get an idea about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>val</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47.750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>45.750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>48.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>48.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>50.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>45.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>47.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>44.330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>44.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>43.750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>43.500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>44.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>44.330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>44.750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>44.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>44.670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>30.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>48.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>41.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>56.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>30.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>51.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>41.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>40.670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>9</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>9</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>9</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>9</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>9</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>9</td>\n",
       "      <td>3.285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>9</td>\n",
       "      <td>3.110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>9</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>9</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>9</td>\n",
       "      <td>3.270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>9</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>9</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>9</td>\n",
       "      <td>3.270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>9</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>9</td>\n",
       "      <td>2.980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>9</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>9</td>\n",
       "      <td>3.270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num     val  activity\n",
       "0             1  47.400       1.0\n",
       "1             1  47.750       1.0\n",
       "2             1  45.750       1.0\n",
       "3             1  48.000       1.0\n",
       "4             1  48.000       1.0\n",
       "5             1  50.000       1.0\n",
       "6             1  33.000       1.0\n",
       "7             1  45.500       1.0\n",
       "8             1  47.500       1.0\n",
       "9             1  45.000       0.0\n",
       "10            1  44.330       0.0\n",
       "11            1  44.250       0.0\n",
       "12            1  43.750       0.0\n",
       "13            1  43.500       0.0\n",
       "14            1  45.000       0.0\n",
       "15            1  44.000       0.0\n",
       "16            1  44.330       0.0\n",
       "17            1  45.000       0.0\n",
       "18            1  44.750       0.0\n",
       "19            1  44.250       0.0\n",
       "20            1  44.670       0.0\n",
       "21            1  30.000       0.0\n",
       "22            1  48.250       0.0\n",
       "23            1  41.000       0.0\n",
       "24            1  40.000       0.0\n",
       "25            1  56.250       0.0\n",
       "26            1  30.000       0.0\n",
       "27            1  51.000       0.0\n",
       "28            1  41.000       0.0\n",
       "29            1  40.670       0.0\n",
       "..          ...     ...       ...\n",
       "591           9   0.700       0.0\n",
       "592           9   0.830       0.0\n",
       "593           9   0.710       0.0\n",
       "594           9   0.820       0.0\n",
       "595           9   0.820       0.0\n",
       "596           9   0.820       0.0\n",
       "597           9   1.090       0.0\n",
       "598           9   0.830       0.0\n",
       "599           9   0.820       0.0\n",
       "600           9   0.500       0.0\n",
       "601           9   0.500       0.0\n",
       "602           9   0.940       0.0\n",
       "603           9   0.830       0.0\n",
       "604           9   0.830       0.0\n",
       "605           9   0.830       0.0\n",
       "606           9   0.830       0.0\n",
       "607           9   0.830       0.0\n",
       "608           9   0.820       0.0\n",
       "609           9   3.285       0.0\n",
       "610           9   3.110       0.0\n",
       "611           9   3.200       0.0\n",
       "612           9   3.080       0.0\n",
       "613           9   3.270       0.0\n",
       "614           9   3.090       0.0\n",
       "615           9   3.015       0.0\n",
       "616           9   3.270       0.0\n",
       "617           9   3.015       0.0\n",
       "618           9   2.980       0.0\n",
       "619           9   3.015       0.0\n",
       "620           9   3.270       0.0\n",
       "\n",
       "[621 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_plot=pd.DataFrame()\n",
    "a=0\n",
    "b=0\n",
    "for cols in train_subset.columns.tolist():\n",
    "    if cols!='activity':\n",
    "        for i in range(0,69):\n",
    "            scatter_plot.loc[a,'feature_num']=str(b+1)\n",
    "            scatter_plot.loc[a,'val']=train_set.loc[i,cols]\n",
    "            if train_set.loc[i,'activity']=='bending':\n",
    "                scatter_plot.loc[a,'activity']=1\n",
    "            else:\n",
    "                scatter_plot.loc[a,'activity']=0\n",
    "            a=a+1\n",
    "        b=b+1\n",
    "            \n",
    "scatter_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scatter_plot['feature_num'],scatter_plot['val'],c=scatter_plot['activity'])\n",
    "plt.plot()\n",
    "#plt.xlabel('features')\n",
    "label=[\"max_avg_rss12\",\"mean_avg_rss12\",\"median_avg_rss12\",\"max_var_rss12\",\"mean_var_rss12\",\"median_var_rss12\",\"max_var_rss23\",\"mean_var_rss23\",\"median_var_rss23\"]\n",
    "plt.xticks(range(10),label,rotation='vertical')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference :\n",
    "#### Yellow depicts Activity-Bending \n",
    "#### Blue depicts Activity-Non-Bending \n",
    "#### Bending has very less number of samples whereas Non-bending has majority of samples. The scatterplot shows class-imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking each time series in the training set into two (approximately) equal length time series. \n",
    "#### Observation: After breaking the data into two, the scatterplots of different classes look more seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_features=['avg_rss12','var_rss12','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in imp_features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,2)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in imp_features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_train=pd.DataFrame(new_dict)\n",
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_plot=pd.DataFrame()\n",
    "a=0\n",
    "b=0\n",
    "for cols in new_train.columns.tolist():\n",
    "    if cols!='activity':\n",
    "        for i in range(0,138):\n",
    "            scatter_plot.loc[a,'feature_num']=str(b+1)\n",
    "            scatter_plot.loc[a,'val']=new_train.loc[i,cols]\n",
    "            if new_train.loc[i,'activity']=='bending':\n",
    "                scatter_plot.loc[a,'activity']=1\n",
    "            else:\n",
    "                scatter_plot.loc[a,'activity']=0\n",
    "            a=a+1\n",
    "        b=b+1\n",
    "            \n",
    "scatter_plot\n",
    "plt.scatter(scatter_plot['feature_num'],scatter_plot['val'],c=scatter_plot['activity'])\n",
    "plt.plot()\n",
    "#plt.xlabel('features')\n",
    "label=[\"max_avg_rss12\",\"mean_avg_rss12\",\"median_avg_rss12\",\"max_var_rss12\",\"mean_var_rss12\",\"median_var_rss12\",\"max_var_rss23\",\"mean_var_rss23\",\"median_var_rss23\"]\n",
    "plt.xticks(range(10),label,rotation='vertical')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking each time series in the training set into l=(1,2...20) time series of approximately equal length and using logistic regression to solve the binary classification problem, using time-domain features. Using 5-fold cross-validation to determine the best value of l.\n",
    "#### Using stratified cross validation to compensate for the problem of class imbalance, as some of the folds may not have any instances of the rare class.\n",
    "\n",
    "#### Using feature ranking with recursive feature elimination and cross-validated selection of the best number of features. (Function used: RFECV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression as log_reg\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_final=[]\n",
    "auc_final=[]\n",
    "feat_final=[]\n",
    "train_in=[]\n",
    "test_in=[]\n",
    "\n",
    "L=range(1,21)\n",
    "for l in range(1,21):\n",
    "    new_dict={}\n",
    "    for f in features:\n",
    "        for e in imp_extract:\n",
    "            new_dict[e+\"_\"+f] = []\n",
    "    new_dict['activity'] = []\n",
    "\n",
    "    for activity in activities:\n",
    "        mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "        for fname in os.listdir(mypath):\n",
    "            df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "            #print(df)\n",
    "            df_split=np.array_split(df,l)\n",
    "            #print(df_split)\n",
    "            for splits in df_split:\n",
    "                for f in features:\n",
    "                    new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                    new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                    new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "                if activity=='bending1' or activity=='bending2':\n",
    "                    new_dict['activity'].append(1)\n",
    "                else:\n",
    "                    new_dict['activity'].append(0)\n",
    "\n",
    "    new_train=pd.DataFrame(new_dict)\n",
    "    data_X=new_train.loc[:,new_train.columns!='activity']\n",
    "    data_y=new_train['activity']\n",
    "\n",
    "    st_kfcv = StratifiedKFold(n_splits=5,shuffle=False)\n",
    "    area_uc=[]\n",
    "    acc=[]\n",
    "    ret_feat=[]\n",
    "    tr_index=[]\n",
    "    vl_index=[]\n",
    "    \n",
    "    for train_index,val_index in st_kfcv.split(data_X,data_y):\n",
    "        X_train, X_val = data_X.iloc[train_index.tolist(),:], data_X.iloc[val_index.tolist(),:]\n",
    "        y_train, y_val = data_y[train_index.tolist()], data_y[val_index.tolist()]\n",
    "    \n",
    "        regressor = log_reg()\n",
    "        rfecv =   RFECV(estimator=regressor, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "        best_features = rfecv.fit(X_train,y_train).ranking_ == 1\n",
    "\n",
    "        regressor1 = log_reg()\n",
    "        X_train = X_train.loc[:,best_features]\n",
    "        X_val = X_val.loc[:,best_features]\n",
    "        regressor1.fit(X_train,y_train)\n",
    "        fpr,tpr,_=roc_curve(y_val,regressor1.predict(X_val))\n",
    "        acc.append(regressor1.score(X_val,y_val))\n",
    "        area_uc.append(auc(fpr, tpr))\n",
    "        ret_feat.append(X_train.columns)\n",
    "        tr_index.append(train_index)\n",
    "        vl_index.append(val_index)\n",
    "        \n",
    "    acc_final.append(np.mean(acc))\n",
    "    auc_final.append(np.mean(area_uc))\n",
    "    q=np.argmax(area_uc)\n",
    "    feat_final.append(ret_feat[q])\n",
    "    train_in.append(tr_index[q])\n",
    "    test_in.append(vl_index[q])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.914021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.883391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>0.881159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.830682</td>\n",
       "      <td>0.901058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.857326</td>\n",
       "      <td>0.909085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.857887</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.848843</td>\n",
       "      <td>0.912903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.826944</td>\n",
       "      <td>0.904348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.826499</td>\n",
       "      <td>0.902536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.834109</td>\n",
       "      <td>0.905893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.903973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.821048</td>\n",
       "      <td>0.907772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.749444</td>\n",
       "      <td>0.876329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.759288</td>\n",
       "      <td>0.885006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.829260</td>\n",
       "      <td>0.907987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.818519</td>\n",
       "      <td>0.900055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.786068</td>\n",
       "      <td>0.897710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.881884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     L       AUC  Accuracy\n",
       "0    1  0.966667  0.942857\n",
       "1    2  0.858333  0.914021\n",
       "2    3  0.819444  0.883391\n",
       "3    4  0.868750  0.920000\n",
       "4    5  0.771111  0.881159\n",
       "5    6  0.830682  0.901058\n",
       "6    7  0.857326  0.909085\n",
       "7    8  0.857887  0.918296\n",
       "8    9  0.848843  0.912903\n",
       "9   10  0.826944  0.904348\n",
       "10  11  0.826499  0.902536\n",
       "11  12  0.834109  0.905893\n",
       "12  13  0.838462  0.903973\n",
       "13  14  0.821048  0.907772\n",
       "14  15  0.749444  0.876329\n",
       "15  16  0.759288  0.885006\n",
       "16  17  0.829260  0.907987\n",
       "17  18  0.818519  0.900055\n",
       "18  19  0.786068  0.897710\n",
       "19  20  0.726667  0.881884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_values = pd.DataFrame({\"L\":L,\"AUC\":auc_final,\"Accuracy\":acc_final})\n",
    "coef_values[['L','AUC','Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features : \n",
      " ['mean_avg_rss12' 'max_var_rss12' 'mean_var_rss12' 'max_avg_rss13'\n",
      " 'mean_avg_rss13' 'median_var_rss13' 'max_avg_rss23' 'mean_avg_rss23'\n",
      " 'max_var_rss23']\n"
     ]
    }
   ],
   "source": [
    "best_features=feat_final[1].values\n",
    "print(\"Best features : \\n\",best_features)\n",
    "\n",
    "train_index=(train_in[1])\n",
    "test_index=(test_in[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "### Best L=1\n",
    "###            Best Features \n",
    " 'mean_avg_rss12', 'max_var_rss12' ,'mean_var_rss12' 'max_avg_rss13','mean_avg_rss13', 'median_var_rss13' ,'max_avg_rss23' 'mean_avg_rss23','max_var_rss23'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix ,ROC and AUC for classifier on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      " 1.0\n",
      "\n",
      "Confusion Matrix :\n",
      " [[19  0]\n",
      " [ 0  2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "train_index=train_in[1]\n",
    "test_index=test_in[1]\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_train=pd.DataFrame(new_dict)\n",
    "data_X=new_train.loc[:,new_train.columns!='activity']\n",
    "data_y=new_train['activity']\n",
    "area_uc = []\n",
    "\n",
    "data_X = data_X[best_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.30, random_state=0) \n",
    "regressor = log_reg()\n",
    "regressor = regressor.fit(X_train, y_train)\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "acc=0\n",
    "\n",
    "for y in y_test.tolist():\n",
    "    if y=='bending':\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(0)\n",
    "for p in regressor.predict(X_test).tolist():\n",
    "    if p=='bending':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)      \n",
    "\n",
    "cm = metrics.confusion_matrix(y_true,y_pred)\n",
    "acc=regressor.score(X_test,y_test)\n",
    "print(\"\\nAccuracy:\\n\",acc)\n",
    "print(\"\\nConfusion Matrix :\\n\",cm)\n",
    "fpr, tpr, _ = roc_curve(y_true,y_pred)\n",
    "area_uc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red',lw=2, label='ROC curve (area = %0.2f)' % area_uc)\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.10])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#print(fpr,tpr)\n",
    "#print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Features and  Regression co-efficient values associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Co-efficient values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_avg_rss12</td>\n",
       "      <td>0.550860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_var_rss12</td>\n",
       "      <td>0.342922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_var_rss12</td>\n",
       "      <td>0.134122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_avg_rss13</td>\n",
       "      <td>0.027537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_avg_rss13</td>\n",
       "      <td>0.210594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>median_var_rss13</td>\n",
       "      <td>0.160376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max_avg_rss23</td>\n",
       "      <td>-0.457070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_avg_rss23</td>\n",
       "      <td>-0.680992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_var_rss23</td>\n",
       "      <td>0.037650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature  Co-efficient values\n",
       "0    mean_avg_rss12             0.550860\n",
       "1     max_var_rss12             0.342922\n",
       "2    mean_var_rss12             0.134122\n",
       "3     max_avg_rss13             0.027537\n",
       "4    mean_avg_rss13             0.210594\n",
       "5  median_var_rss13             0.160376\n",
       "6     max_avg_rss23            -0.457070\n",
       "7    mean_avg_rss23            -0.680992\n",
       "8     max_var_rss23             0.037650"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame({\"Feature\":best_features,\"Co-efficient values\":regressor.coef_[0].tolist()})\n",
    "coef[['Feature','Co-efficient values']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Features and p-values associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_avg_rss12</td>\n",
       "      <td>5.004041e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_var_rss12</td>\n",
       "      <td>1.766010e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_var_rss12</td>\n",
       "      <td>1.524376e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_avg_rss13</td>\n",
       "      <td>4.948314e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_avg_rss13</td>\n",
       "      <td>1.396682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>median_var_rss13</td>\n",
       "      <td>3.894605e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max_avg_rss23</td>\n",
       "      <td>1.369210e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_avg_rss23</td>\n",
       "      <td>5.878163e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_var_rss23</td>\n",
       "      <td>8.058217e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature      P-values\n",
       "0    mean_avg_rss12  5.004041e-01\n",
       "1     max_var_rss12  1.766010e-03\n",
       "2    mean_var_rss12  1.524376e-02\n",
       "3     max_avg_rss13  4.948314e-02\n",
       "4    mean_avg_rss13  1.396682e-01\n",
       "5  median_var_rss13  3.894605e-02\n",
       "6     max_avg_rss23  1.369210e-09\n",
       "7    mean_avg_rss23  5.878163e-10\n",
       "8     max_var_rss23  8.058217e-02"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,p=chi2(X_train,y_train)\n",
    "coef_values = pd.DataFrame({\"Feature\":best_features,\"P-values\":p})\n",
    "coef_values[['Feature','P-values']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the classifier on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the Test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_train=pd.DataFrame(new_dict)\n",
    "#new_train= new_train.sample(frac=1,random_state=5).reset_index(drop=True)\n",
    "data_X=new_train.loc[:,new_train.columns!='activity']\n",
    "data_y=new_train['activity']\n",
    "\n",
    "data_X = data_X[best_features]\n",
    "train_X=data_X\n",
    "train_y=data_y\n",
    "#print(new_train)\n",
    "#print(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/test\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_test=pd.DataFrame(new_dict)\n",
    "\n",
    "data_X=new_test.loc[:,new_test.columns!='activity']\n",
    "test_X=data_X[best_features]\n",
    "test_y=new_test['activity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the classifier with best features extracted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Test data:\n",
      " [[15  0]\n",
      " [ 0  4]]\n",
      "\n",
      "Area under curve for Test data:\n",
      " 1.0\n",
      "\n",
      "Accuracy:\n",
      " 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VNXWwOHfSiGhhF5EgvTeISCIIl1UFBEURP0QUWyANBURuQpWRECKBRXBilfvpejFK4IgRUBAkA4JyIUgJUAIARJIWd8fM4YQkskAmZlkst7nycOcM3v2WXNIZs3e+5y9RVUxxhhjshLg6wCMMcbkbpYojDHGuGSJwhhjjEuWKIwxxrhkicIYY4xLliiMMca4ZInCGGOMS5YojF8RkX0ikiAip0XksIjMEpEiGcrcICI/i0i8iMSJyHciUjdDmaIiMllE9jvrinJul87iuCIig0Vkq4icEZFoEflGRBp48v0a4w2WKIw/ukNViwCNgSbA838/ISKtgEXAfOBaoArwB7BKRKo6yxQAlgD1gC5AUeAG4DjQIotjvgM8DQwGSgI1gXnA7ZcbvIgEXe5rjPEksTuzjT8RkX3AI6q62Lk9Hqinqrc7t1cAW1T1yQyv+wGIUdX/E5FHgFeBaqp62o1j1gB2Aq1U9bcsyiwDPlfVj5zbDznjvNG5rcBAYAgQBPwInFbVEenqmA/8oqoTReRaYCrQBjgNTFLVKW6cImMum7UojN8SkXDgViDKuV0IR8vgm0yK/xPo5HzcEfivO0nCqQMQnVWSuAx3AdcDdYEvgV4iIgAiUgLoDMwRkQDgOxwtoQrO4w8RkVuu8vjGZMoShfFH80QkHjgAHAX+4dxfEsfv/KFMXnMI+Hv8oVQWZbJyueWz8rqqnlDVBGAFoMBNzud6AqtV9S+gOVBGVceq6nlV3Qt8CPTOgRiMuYQlCuOP7lLVMKAtUJsLCSAWSAXKZ/Ka8sAx5+PjWZTJyuWWz8qBvx+oo094DnCfc1cf4Avn40rAtSJy8u8fYBRQLgdiMOYSliiM31LVX4BZwATn9hlgNXBPJsXvxTGADbAYuEVECrt5qCVAuIhEuChzBiiUbvuazELOsP0V0FNEKuHokvqXc/8B4E9VLZ7uJ0xVb3MzXmMuiyUK4+8mA51EpLFzeyTQ13kpa5iIlBCRV4BWwMvOMp/h+DD+l4jUFpEAESklIqNE5JIPY1WNBN4FvhKRtiJSQERCRaS3iIx0FtsE3C0ihUSkOtA/u8BVdSMQA3wE/KiqJ51P/QacEpHnRKSgiASKSH0RaX4lJ8iY7FiiMH5NVWOAT4EXndsrgVuAu3GMK/wPxyW0Nzo/8FHVczgGtHcCPwGncHw4lwbWZnGowcA0YDpwEtgDdMcx6AwwCTgPHAFmc6EbKTtfOWP5Mt17SgHuwHH57584usw+Aoq5Wacxl8UujzXGGOOStSiMMca4ZInCGGOMS5YojDHGuGSJwhhjjEt5bvKx0qVLa+XKlX0dhjHG5CkbNmw4pqplruS1eS5RVK5cmfXr1/s6DGOMyVNE5H9X+lrrejLGGOOSJQpjjDEuWaIwxhjjkiUKY4wxLlmiMMYY45IlCmOMMS5ZojDGGOOSJQpjjDEuWaIwxhjjkiUKY4wxLlmiMMYY45IlCmOMMS5ZojDGGOOSJQpjjDEuWaIwxhjjkscShYjMFJGjIrI1i+dFRKaISJSIbBaRpp6KxRhjzJXzZItiFtDFxfO3AjWcPwOA9zwYizHGmCvksRXuVHW5iFR2UaQb8KmqKrBGRIqLSHlVPeSy4g0bQCTnAjXGGD+2isrsoOxV1eHLpVArAAfSbUc7912SKERkAI5WB828EpoxxuRthwjjWW7nc5oRQhLw2xXX5ctEkVmzQDMrqKozgBkAERERiq2ZbYwxmTp/PoV33tnA2LGrOX06iZCQQJ59tiXjxl15nb5MFNFAxXTb4cBfPorFGGPyvMWL/8fAgUvYtesEAN26VWfixLZUrVr8qhKFLy+PXQD8n/Pqp5ZAXLbjE8YYY7K0atVBdu06Qc2aJfjhhx7Mm3cXVasWv+p6PdaiEJGvgLZAaRGJBv4BBAOo6vvAQuA2IAo4C/TzVCzGGOOPzp5NYufOEzRtWg6AZ59tTsmSoTz2WCMKFAjMseOI46KjvCMiIkLX2xiFMSYfU1Xmzo1k6NClJCamsHt3f4oVC3H5GhHZoKoRV3I8uzPbGGPykB07jtO587f06LGA/fvjKV++MIcPn/HoMX05mG2MMcZNp06d4+WXf2XKlI0kJ6dSokQor7zSmgEDGhEU5Nnv/JYojDEmD7jrrnksXXoAEXjssUa88kprSpcu5JVjW6IwxphcSlUR50wUo0a15Ny5FKZO7ZA2eO0tliiMMSaXOXbsLKNGrQRgxozOAHTsWIkOHa5LSxzeZIPZxhiTSyQnpzJ9+kZq1PiYDz/czOzZ2zh4MD7teV8kCbAWhTHG5AorVkQzcOASNm+OAaBTp0q88057KlQI83FkliiMMcanUlJS6dv3B774YgcAlSoVZdKkdtx1V3WftSAyskRhjDE+FBgYQHBwAKGhQYwc2YJnn21OwYLBvg7rInZntjHGeNkPP+ylaNEQWreuAMDRo2c4ezaZypWLeeyYV3NntrUojDHGS/bsOcnQoUv57rs91KtXio0b/4/g4EDKli3s69BcskRhjDEedubMeV5//TcmTFjHuXMpFCkSTL9+9X0dltssURhjjIeoKt98s4sRI37hwAHHZa4PPliXN99sQ/nyRXwcnfssURhjjIfEx5/nqaeWcOxYAk2alGXatA7ccEMFX4d12SxRGGNMDoqLO0dISCChoUEULRrCO++0Jz7+PI880oDAwLx5j3PejNoYY3KZ1FTlk0+2ULPmx0yYsC5tf58+dXjssUZ5NkmAtSiMMeaqrVt3iEGDfmbtWsdqzitWHLxoQr+8zhKFMcZcoZiYszz//ApmztyCKpQvX5i33rqZPn3q+E2SAEsUxhhzRfbsOUlExGecPHmO4OAAhg5txujRrQgLK+Dr0HKcJQpjjLkCVasWo3HjsoSGBjJ5cntq1Srp65A8Ju+OrhhjjBcdOHCKPn2+Z9euE4Bjyu8FC7qzcGEPv04SYC0KY4xxKTExmbffXs9rr63h7NlkzpxJYv787gB+2c2UGUsUxhiThe+/38OQIUvZs+ckAD171mTChJt9HJX3WaIwxpgM9u2L46mnFrNw4Z8A1K1biilT2tOhQyUfR+YbliiMMSaDlBRlyZL9FC1agJdfbs1TTzUmODjQ12H5jCUKY0y+p6r8979/0qVLFUSEatWK89VXXbnhhmspVy53TwHuDXbVkzEmX9u8OYZ27b7mttv+zeefb0/b3717DUsSTtaiMMbkS7GxiYwZs4p3391EaqpSunTBfN295IolCmNMvpKSksrMmVsZNWoFx44lEBAgDBrUhJdfbk2JEqG+Di9XskRhjMlXZs3axoABiwBo0yacqVM70LBhGR9HlbtZojDG+L3k5FSCghxDsg88UIcvv9zBo482pFevWn41eZ+neHQwW0S6iMguEYkSkZGZPH+diCwVkY0isllEbvNkPMaY/CUpKYXJkzdQs+bHHDt2FoCQkCCWLLmX3r1rW5Jwk8cShYgEAtOBW4G6wH0iUjdDsdHAP1W1CdAbeNdT8Rhj8peff95P48afMnToUv78M445c3b6OqQ8y5NdTy2AKFXdCyAic4BuwPZ0ZRQo6nxcDPjLg/EYY/KB/ftPMXz4Mr79djcA1aoVZ/LkdnTtWs3HkeVdnkwUFYAD6bajgeszlHkJWCQig4DCQMfMKhKRAcAAgOuuuy7HAzXG+IdZs7by5JOLSUhIplChIF54oSXDhkUQGmrDsVfDk2MUmXX+aYbt+4BZqhoO3AZ8JiKXxKSqM1Q1QlUjypSxqxOMMZmrXr04CQnJ3HtvLXbufJhRo1paksgBnjyD0UDFdNvhXNq11B/oAqCqq0UkFCgNHPVgXMYYP7Fr1wm+/34Pw4c3B+DGG8PZtu0h6tYt7ePI/IsnWxTrgBoiUkVECuAYrF6Qocx+oAOAiNQBQoEYD8ZkjPED8fHnee65X2jQYBYjRvzC8uUXerktSeQ8j7UoVDVZRAYCPwKBwExV3SYiY4H1qroAGA58KCJDcXRLPaSqGbunjDEGcEze9+WXO3jmmV84dOgMItC/fwNq1/bvFeZ8za1E4WwRXKeqUZdTuaouBBZm2Dcm3ePtQOvLqdMYkz9t2nSUQYOWsHLlQQBatLiGadM60Lx5eR9H5v+y7XoSkduBLcBPzu3GIjLX04EZY0x6M2b8wcqVBylbthAzZ97C6tX3W5LwEndaFGNxXNa6FEBVN4lIdY9GZYzJ91JSUomOjqdSpWIAjBt3I0WLhjByZAuKF7fJ+7zJncHsJFU9mWGfjSMYYzzm118P0qLFF3Ts+A3nziUDUKpUQd54o40lCR9wJ1HsEJF7gQDnFUyTgTUejssYkw8dPnyGvn0X0rr1V/z++xESE1PYsyfj91Tjbe4kioFAMyAV+DeQCDztyaCMMfnL+fMpvP32OmrW/JhPP91OgQKBvPBCS3bu7GeXu+YC7oxR3KKqzwHP/b1DRO7GkTSMMeaq3Xbbv1iyZD8Ad9xRjUmT2lGtWnEfR2X+5k6LYnQm+17I6UCMMflXv371qVGjBAsX3s2CBd0tSeQyWbYoROQWHNNrVBCRiemeKoqjG8oYYy5bQkIS48evIyBAePHFVgD06VOHnj1rEhJi8zLlRq7+V44CW3GMSWxLtz8euGQRImOMcUVVmTcvimHDlrJv3ylCQgIZMKAh5coVRkQsSeRiWf7PqOpGYKOIfKGqiV6MyRjjZ3buPM7TTy9l0aJ9ADRsWIZp0zpQrlxh3wZm3OJOCq8gIq/iWKUu7QJmVa3psaiMMX4hOTmV559fzuTJv5OcnErx4iG88sqNPPZYo7Q1rE3u506imAW8AkzAsaxpP2yMwhjjhsBAYdu246SkpPLoow159dUbKVOmkK/DMpfJnURRSFV/FJEJqroHGC0iKzwdmDEmb/r99yMULBhEnTqlEBGmTu1AbGwiERHX+Do0c4XcSRTnRESAPSLyOHAQKOvZsIwxec2xY2d54YWVfPjhZm66KZxly3ohInapqx9wJ1EMBYoAg4FXgWLAw54MyhiTd6SkpPLBB38wevQqYmMTCQoKICKiHElJqRQoEOjr8EwOyDZRqOpa58N44EEAEQn3ZFDGmLxhxYpoBg1awh9/OBam7NixElOmtKdOnVI+jszkJJeJQkSaAxWAlap6TETq4ZjKoz2ONbCNMflUbGwit976L86cSaJSpaJMnNiW7t1r4OipNv7E1Z3ZrwM9gD9wDGDPxTEZ4JvA494JzxiTm5w/n0JgoBAYGECJEqG8/PINnDp1nueea0GhQsG+Ds94iKsWRTegkaomiEhJ4C/n9i7vhGaMyU3++98/efrpnxkxojmPPtoQgOHDm/s4KuMNru54SVTVBABVPQHstCRhTP6zd+9JunWby623/ovdu2OZPXsbqrZ2WX7iqkVRVUT+nkpcgMrptlHVuz0amTHGp86eTeKNN9Yyfvw6zp1LoUiRYMaMacXTTzezcYh8xlWi6JFhe5onAzHG5B6RkbF07PhP9u+PB+CBB+ry5pttuPbaIj6OzPiCq0kBl3gzEGNM7lGlSjGKFg2hceOCTJvWgdatK/g6JONDNiuXMYa4uHM8++wvHDp0GoCgoAB++KEH69c/YEnCuHVntjHGT6WmKrNnb2XkyBUcPXqWI0fOMHv2bQCEh4f5ODqTW7idKEQkRFXPeTIYY4z3rF9/mIEDl7B27SEAWreuwJAhzXwclcmNsu16EpEWIrIFiHRuNxKRqR6PzBjjETExZ3n00R9p0eJz1q49RPnyhfn889tYsaI3TZqU83V4Jhdyp0UxBegKzANQ1T9EpJ1HozLGeMy+fXF8/PEWgoICGDKkGS++2IqwsAK+DsvkYu4kigBV/V+G66ZTPBSPMcYDtm6NoX79MgA0b16eKVPa06lTZWrVKunjyExe4M5VTwdEpAWgIhIoIkOA3R6OyxiTA6Kj47nvvu9p0GB22nrVAAMHNrUkYdzmTqJ4AhgGXAccAVo692VLRLqIyC4RiRKRkVmUuVdEtovINhH50t3AjTFZO3cumddfX0utWh8zZ85OQkOD2LcvztdhmTzKna6nZFXtfbkVi0ggMB3oBEQD60RkgapuT1emBvA80FpVY0XEVs4z5ir95z97GDJkKVFRJwHo0aMGb7/dlkqVivk4MpNXuZMo1onILuBr4N+qGu9m3S2AKFXdCyAic3DMSLs9XZlHgemqGgugqkfdjtwYc4mPPtrMo48uAqBOnZJMmdKBjh0r+Tgqk9dl2/WkqtWAV4BmwBYRmSci7rQwKgAH0m1HO/elVxOoKSKrRGSNiHTJrCIRGSAi60VkfUxMjBuHNiZ/uvfeWtSsWYKJE9vyxx99LUmYHOHWFB6q+quqDgaaAqeAL9x4WWbTS2acmzgIqAG0Be4DPhKRS1ZiV9UZqhqhqhFlypRxJ2Rj/J6q8vXXO7nxxq84ezYJgKJFQ9i+vR9Dh0YQHGzrVZuc4c4Nd0VE5H4R+Q74DYgBbnCj7migYrrtcByLH2UsM19Vk1T1T2AXjsRhjHFhy5YY2rf/J717f8+qVQeZOXNL2nOBgTaFm8lZ7oxRbAW+A8ar6orLqHsdUENEqgAHgd5Anwxl5uFoScwSkdI4uqL2XsYxjMlXTp5MZMyYVbz77iZSUpRSpQry2ms30r9/A1+HZvyYO4miqqqmXm7FqposIgOBH4FAYKaqbhORscB6VV3gfK6ziGzHcRPfM6p6/HKPZUx+8O23u3jyycXExCQQECA89VRjxo5tTcmSBX0dmvFzWSYKEXlbVYcD/xKRS9Y9dGeFO1VdCCzMsG9MuseK4x6NYZcTtDH5UUCAEBOTwE03hTN1ansaNbKryY13uGpRfO3811a2M8YHjhw5w7JlB+jVqzYA3bvXYNGinnTsWMmWIjVe5WqFu9+cD+uo6kXJwtmlZCvgGeMBSUkpvPvuJsaMWcWZM0nUr1+aevVKIyJ06lTZ1+GZfMidyyMezmRf/5wOxBgDS5fup0mTTxkyZCmnTp2nc+fKFCxo64sZ33I1RtELx5VKVUTk3+meCgNOejowY/KT/ftPMWLEMr75xjHfZtWqxZg8uT1du1a1bibjc66+qvwGHMdx/8P0dPvjgY2eDMqY/GbkyOV8881uChYM4oUXWjJ8eAShodaSMLmDqzGKP4E/gcXeC8eY/EFVOXXqPMWKhQDw+us3ERAgvP76TVSsWNTH0RlzMVddT7+o6s0iEsvFU28IjitbbTJ7Y67A7t0nGDJkKcePJ7B69f0EBAiVKhXj889v93VoxmTKVdv27+VOS3sjEGP83enT53nllTVMnLiepKRUihULYdeuE9SpU8rXoRnjUpZXPaW7G7siEKiqKUAr4DGgsBdiM8YvqCpffrmDWrVm8uabv5GUlMrDD9dn9+6HLUmYPMGd0bJ5QHMRqQZ8CvwH+BLo6snAjPEHqkq3bvP47rs9ADRvfg1Tp3bg+uvL+zgyY9znzn0UqaqaBNwNTFbVQVy6roQxJhMiQtu2FSlTpiAffXQLa9bcb0nC5DluLYUqIvcADwJ3OfcFey4kY/KulJRUPv54C0FBATz8sGNG10GDmtCvX31KlAj1cXTGXBl3EsXDwJM4phnf65w2/CvPhmVM3rN69V8MGrSEDRuOUKxYCN26VadUqYIEBwdSooQtImTyrmwThapuFZHBQHURqY1jHexXPR+aMXnD4cNnGDlyObNnbwMgPDyMCRNupmRJa0EY/5BtohCRm4DPcCw+JMA1IvKgqq7ydHDG5GbJyalMmfI7L730K/Hx5ylQIJARIyIYNep6Chcu4OvwjMkx7nQ9TQJuU9XtACJSB0fiiPBkYMbkdgEBwldf7SA+/jxdu1Zl0qR2VK9ewtdhGZPj3EkUBf5OEgCqukNE7OuSyZf27YsjODiAChXCCAgQ3nuvE0eOnOH226v5OjRjPMady2N/F5EPRORG58972KSAJp9JSEji5Zd/pU6dTxg6dGna/oiIayxJGL/nTovicWAw8CyOMYrlwFRPBmVMbqGqzJsXxbBhS9m37xQAgYEBJCWlEBxsVzKZ/MFlohCRBkA1YK6qjvdOSMbkDjt3Hufpp5eyaNE+ABo0KM3UqR24+eaKvg3MGC9zNXvsKBwr2f2OYwqPsao602uRGeNDMTFnadLkMxITkylePIRx41rz+OONCQpyp7fWGP/iqkVxP9BQVc+ISBlgIWCJwvgtVcds+iJCmTKFeOyxhpw9m8yrr95ImTKFfBydMb7j6uvROVU9A6CqMdmUNSZP27jxCDfdNIcFC/ak7Zs0qR0zZnS2JGHyPVctiqrp1soWoFr6tbNV9W6PRmaMFxw/nsDo0SuZMWMzqalKSkoq3bpVB7C1qo1xcpUoemTYnubJQIzxppSUVGbM2Mzo0Ss5cSKRwEBh6NBm/OMfN/g6NGNyHVdrZi/xZiDGeMuePSfp2XMBmzYdBaB9++uYMqU99erZYo7GZMad+yiM8SvXXFOIY8cSuO66MN5+uy09etS0biZjXLBEYfze+fMpvP/+H/TrV5+wsAIULlyAhQvvplq14hQqZEurGJMdtxOFiISo6jlPBmNMTlu0aB+DB//Mrl0niI6OZ/z4mwFo0KCMjyMzJu/I9pJXEWkhIluASOd2IxGxKTxMrvbnnyfp3n0et9zyLbt2naBmzRJ07FjJ12EZkye506KYAnQF5gGo6h8i0s6jURlzhc6eTeLNN39j/Ph1JCYmU6RIMGPGtOLpp5tRoIDNzWTMlXDnJroAVf1fhn0p7lQuIl1EZJeIRInISBfleoqIioitcWGuyqpVBxk7djWJicncf38ddu3qzzPPtLAkYcxVcKdFcUBEWgAqIoHAIGB3di9ylp0OdAKigXUisiD92hbOcmE4Zqdde7nBGwNw9OgZypYtDECnTpUZMSKCO++szk03hfs4MmP8gzstiieAYcB1wBGgpXNfdlrgWF97r6qeB+YA3TIpNw4YDyS6FbExTnFx5xg2bCkVK87g99+PpO1/6622liSMyUHZJgpVPaqqvVW1tPOnt6oec6PuCsCBdNvRzn1pRKQJUFFVv3dVkYgMEJH1IrI+JibGjUMbf5aaqsyevZVatT5m0qQNJCWl8MsvB7J/oTHmimTb9SQiHwKacb+qDsjupZnsS6tHRAJwrMf9UHYxqOoMYAZARETEJbGY/GPDhsMMHLiENWsOAXDDDdcydWoHmjYt5+PIjPFf7oxRLE73OBTozsUthaxEA+lXeAkH/kq3HQbUB5Y574q9BlggIneq6no36jf5zCefbKF//x9RhWuuKcz48W144IG6dle1MR6WbaJQ1a/Tb4vIZ8BPbtS9DqghIlWAg0BvoE+6euOAtMl1RGQZMMKShMnKLbdUoXjxUPr3r8+LL7aiaNEQX4dkTL5wJVN4VAGyvXNJVZNFZCDwIxAIzFTVbSIyFlivqguu4NgmH1m+/AAffLCZ2bNvJSgogGuvLcL//jeAsLACvg7NmHzFnTGKWC6MLQQAJ4As74lIT1UX4lgZL/2+MVmUbetOncb/HTwYzzPP/MJXX+0EoF27ijzySEMASxLG+IDLRCGOzt9GOLqOAFL17/Uijclh584lM2nSBl55ZQ1nziQRGhrEyJEtuP/+Or4OzZh8zWWiUFUVkbmq2sxbAZn86aef9vHUU0uIjIwFoHv3Gkyc2JbKlYv5ODJjjDtjFL+JSFNV/d3j0Zh8KyrqJJGRsdSuXZIpU9rTqVNlX4dkjHHKMlGISJCqJgM3Ao+KyB7gDI77I1RVm3opRuOHzp5NYsOGI2l3UA8Y0JCQkEAeeKCuzctkTC7jqkXxG9AUuMtLsZh8QFX59tvdDB++jBMnEtm162EqVAgjMDCAhx9u4OvwjDGZcJUoBEBV93gpFuPntm07xuDBP/Pzz/sBaNq0HCdPnqNChTAfR2aMccVVoigjIsOyelJVJ3ogHuOHTp5M5KWXfmXatI2kpCilShXk1Vdv5JFHGhAY6M68lMYYX3KVKAKBImQ+Z5MxbuvX77/MmxdFQIDw5JONGTeuNSVLFvR1WMYYN7lKFIdUdazXIjF+JTk5laAgR2vhH/+4gdjYRCZPbk/jxmV9HJkx5nJlO0ZhzOU4evQMzz+/gmPHEpg/vzsAjRuXZdmy3j6OzBhzpVwlig5ei8LkecnJqbz77ibGjFlFXNw5goMD2L37BDVrlvR1aMaYq5RlolDVE94MxORdy5btZ9Cgn9m61bGeVZculZk8ub0lCWP8xJXMHmsM4Lgnom/fH/jsM8cy6FWrFmPSpHbccUc1WyPCGD9iicJcMRGhfPnCFCwYxKhR1zNiRHNCQ+1Xyhh/I3ltMtiIiAhdv97WNvKV77/fgwjcfns1AOLjzxMbm8h11xX1cWTGGFdEZIOqRlzJa+3rn3FLZGQsQ4b8zMKFf1KhQhF27qxIkSIFCAsrYGtEGOPnLFEYl06fPs+rr65h4sQNnD+fQtGiBRg+PIKQEJu4z5j8whKFyZSq8vXXuxgxYhkHD54G4KGH6vHGG20oV66wj6MzxniTJQqTqfPnU3jhhRUcPHiaiIhyTJ3agZYtr/V1WMYYH7BEYdLExiYiAsWLhxISEsT06R2Jjo7n4YcbEBBgl7sak1/Z1J2GlJRUPvxwMzVrfszo0SvT9nfpUoVHHmloScKYfM5aFPnc2rWHGDhwMevXHwFg584TF03oZ4wxlijyqSNHzjBy5HJmzdoGQHh4GBMm3My999ayu6qNMRexRJEPHT58hlq1PubUqfMUKBDIiBERjBp1PYUL2/0QxphLWaLIh665pjC33lqF06eTmDy5HdWrl/B1SMaYXMw6ovOB/ftPce+9C/j114Np+2bNupXvv7/bkoQxJlvWovBjiYnJvPXWOl5/fS0JCckcPnyW5csdCwjZ5H3GGHfZp4UfUlUWLNjD0KFL+fPPOAB69arFW29dvZnQAAAWXklEQVTd7OPIjDF5kSUKP7N//ykGDFjEjz/uA6B+/dJMndqetm2v821gxpg8yxKFnylYMIi1aw9RrFgI48a15oknGts9EcaYq+LRTxAR6SIiu0QkSkRGZvL8MBHZLiKbRWSJiFTyZDz+SFX59793c/58CgBlyhTi22/vZPfuhxk0qKklCWPMVfPYp4iIBALTgVuBusB9IlI3Q7GNQISqNgS+BcZ7Kh5/tGnTUdq0mUOPHguYOvX3tP0dOlSibFmb4dUYkzM8+XWzBRClqntV9TwwB+iWvoCqLlXVs87NNUC4B+PxGydOJPDkkz/RrNlnrFx5kDJlCnLNNZYYjDGe4ckxigrAgXTb0cD1Lsr3B37I7AkRGQAMALjuuvw7KJuSkspHH23hhRdWcvx4AoGBwtNPN+Wll26gePFQX4dnjPFTnkwUmU0YlOkC3SLyABABZHr9pqrOAGaAY83snAowr5k/P4rHH/8JgHbtKjJlSnvq1y/j46iMMf7Ok4kiGqiYbjsc+CtjIRHpCLwA3Kyq5zwYT56UmJicdnPcXXfV4J57anLPPbXo2bOmTd5njPEKT45RrANqiEgVESkA9AYWpC8gIk2AD4A7VfWoB2PJc86fT2HChHVcd90H7N17EoCAAOGf/7yTe+6xGV6NMd7jsUShqsnAQOBHYAfwT1XdJiJjReROZ7G3gCLANyKySUQWZFFdvvLTT/to1Gg2zzzzCzExCfzzn7t8HZIxJh/z6A13qroQWJhh35h0jzt68vh5zb59cQwbtoy5cyMBqFGjBO+8045bb63q48iMMfmZ3ZmdS3z55Q769/+RxMRkChcO5sUXWzJkSDNCQuy/yBjjW/YplEs0blyGlJRU+vSpw/jxbahQIczXIRljDGCJwmd27jzOp59u59VXb0REqFu3NJGR/alUqZivQzPGmItYovCyU6fOMXbsat5553eSk1Np1qwcPXrUBLAkYYzJlSxReElqqvL559t57rnlHD58BhEYMKAhN99ss5YYY3I3SxRe8PvvRxg0aAm//uq437BVq2uZOrU9zZpd4+PIjDEme5YovOC77/bw669/Ua5cIcaPv5kHHqhLQIDdMGeMyRssUXhASkoqkZGx1K5dCoBnn20OwNChzShaNMSXoRljzGWzVW1y2MqV0TRr9hk33/w1cXGOqasKFgzmH/+4wZKEMSZPskSRQ/766zQPPPAfbrppDn/8EUNoaGDaHE3GGJOXWdfTVTp/PoXJkzcwbtxqTp9OIiQkkOeea8Fzz7WgUKFgX4dnjDFXzRLFVbr33u+YPz8KgLvuqs7EiW2pUqW4j6MyuUFSUhLR0dEkJib6OhSTj4SGhhIeHk5wcM59UbVEcZUGDmzCzp0nmDKlPZ07V/Z1OCYXiY6OJiwsjMqVK9u08MYrVJXjx48THR1NlSpVcqxeSxSX4ezZJF5/fS0nTiQyfbpj4tuOHSuxdetDBAXZcI+5WGJioiUJ41UiQqlSpYiJicnRei1RuEFV+fbb3QwfvowDB+IRgeHDI6ha1dHFZEnCZMWShPE2T/zOWaLIxrZtxxg8+Gd+/nk/AI0bl2XatA5pScIYY/ydfRXOgqoybNhSGjWazc8/76dkyVDee68j69c/QOvWFXwdnjFuCQwMpHHjxtSvX5877riDkycvXLK9bds22rdvT82aNalRowbjxo1DVdOe/+GHH4iIiKBOnTrUrl2bESNG+OItuLRx40YeeeQRX4eRpePHj9OuXTuKFCnCwIEDsyx34sQJOnXqRI0aNejUqROxsbGA43No8ODBVK9enYYNG/L7778DEBMTQ5cuXbzyHsASRZZEhBMnElGFJ55oxO7d/Xn88cYEBtopM3lHwYIF2bRpE1u3bqVkyZJMnz4dgISEBO68805GjhzJ7t27+eOPP/j111959913Adi6dSsDBw7k888/Z8eOHWzdupWqVXN2pcXk5OSrruO1115j0KBBXj3m5QgNDWXcuHFMmDDBZbk33niDDh06EBkZSYcOHXjjjTcAR7KOjIwkMjKSGTNm8MQTTwBQpkwZypcvz6pVqzz+HgBHxspLP82aNVNPWbfukK5Z81fa9uHDp3XjxiMeO57xb9u3b7+wAZ75yUbhwoXTHr/33nv6xBNPqKrqRx99pA8++OBFZaOiojQ8PFxVVR988EH9+OOPs60/Pj5eH3roIa1fv742aNBAv/3220uO+80332jfvn1VVbVv3746dOhQbdu2rQ4ZMkQrVaqksbGxaWWrVaumhw8f1qNHj+rdd9+tERERGhERoStXrrzk2KdOndKaNWumba9du1ZbtWqljRs31latWunOnTtVVfWTTz7Rnj17ateuXbVdu3aqqjp+/HiNiIjQBg0a6JgxY9Lq6NatmzZt2lTr1q2rH3zwQbbv312ffPKJPvXUU1k+X7NmTf3rL8dnz19//ZX2vgYMGKBffvllpuXmzZuX9v+Z0UW/e07Aer3Cz10bowBiYs4yatQKPv54C3XrlmLjxv8jODiQcuUKU65cYV+HZ8xVS0lJYcmSJfTv3x9wdDs1a9bsojLVqlXj9OnTnDp1iq1btzJ8+PBs6x03bhzFihVjy5YtAGldJq7s3r2bxYsXExgYSGpqKnPnzqVfv36sXbuWypUrU65cOfr06cPQoUO58cYb2b9/P7fccgs7duy4qJ7169dTv379tO3atWuzfPlygoKCWLx4MaNGjeJf//oXAKtXr2bz5s2ULFmSRYsWERkZyW+//Yaqcuedd7J8+XLatGnDzJkzKVmyJAkJCTRv3pwePXpQqlSpi447dOhQli5desn76t27NyNHjsz2/WfmyJEjlC9fHoDy5ctz9OhRAA4ePEjFihXTyoWHh3Pw4EHKly9PREQEo0ePvqLjXa58nSiSk1N5771NjBmzipMnzxEcHMBtt1UlOTmV4OBAX4dn/Em6vn9vSkhIoHHjxuzbt49mzZrRqVMnZzia5dUxl3PVzOLFi5kzZ07adokSJbJ9zT333ENgoOPvq1evXowdO5Z+/foxZ84cevXqlVbv9u3b015z6tQp4uPjCQu7sETwoUOHKFOmTNp2XFwcffv2JTIyEhEhKSkp7blOnTpRsmRJABYtWsSiRYto0qQJAKdPnyYyMpI2bdowZcoU5s6dC8CBAweIjIy8JFFMmjTJvZOTAzST35u//3/Kli3LX3/95ZU48m2i+OWXAwwatIQtW44B0LlzZaZMaU+tWiV9HJkxOefvMYq4uDi6du3K9OnTGTx4MPXq1WP58uUXld27dy9FihQhLCyMevXqsWHDBho1auSy/qwSTvp9Ge9ML1z4Qiu9VatWREVFERMTw7x589K+IaemprJ69WoKFizo8r2lr/vFF1+kXbt2zJ07l3379tG2bdtMj6mqPP/88zz22GMX1bds2TIWL17M6tWrKVSoEG3bts30rnpPtCjKlSvHoUOHKF++PIcOHaJs2bKAowVx4MCBtHLR0dFce+21gOO8ujo/OSlfjsyePZvEPfcsYMuWY1SuXJS5c7vx3//2sCRh/FaxYsWYMmUKEyZMICkpifvvv5+VK1eyePFiwNHyGDx4MM8++ywAzzzzDK+99hq7d+8GHB/cEydOvKTezp07M23atLTtv7ueypUrx44dO9K6lrIiInTv3p1hw4ZRp06dtG/vGevdtGnTJa+tU6cOUVFRadtxcXFUqOC4InHWrFlZHvOWW25h5syZnD59GnB07xw9epS4uDhKlChBoUKF2LlzJ2vWrMn09ZMmTWLTpk2X/FxpkgC48847mT17NgCzZ8+mW7duafs//fRTVJU1a9ZQrFixtC6q3bt3X9T15kn5JlGcO5fMuXOOKx4KFQpmwoS2vPzyDWzf3o+77qphN0YZv9ekSRMaNWrEnDlzKFiwIPPnz+eVV16hVq1aNGjQgObNm6ddwtmwYUMmT57MfffdR506dahfvz6HDh26pM7Ro0cTGxtL/fr1adSoUdo37TfeeIOuXbvSvn37tA+2rPTq1YvPP/88rdsJYMqUKaxfv56GDRtSt25d3n///UteV7t2beLi4oiPjwfg2Wef5fnnn6d169akpKRkebzOnTvTp08fWrVqRYMGDejZsyfx8fF06dKF5ORkGjZsyIsvvkjLli2zP6luqFy5MsOGDWPWrFmEh4endak98sgjrF+/HoCRI0fy008/UaNGDX766ae0pHPbbbdRtWpVqlevzqOPPpp2VRrA0qVLuf3223MkxuxIZn1guVlERIT+fXLd9Z//7GHIkKX07VuP0aNbeSgyYy62Y8cO6tSp4+sw/NqkSZMICwvL1fdSeEqbNm2YP39+puNCmf3uicgGVY24kmP5dYsiKiqWO+74N127ziUq6iTz50eRmpq3EqMxJmtPPPEEISH5b0GwmJgYhg0b5tbFAznBLxPFmTPneeGFFdSrN4vvv99L0aIFmDixLb/+2sfWqjbGj4SGhvLggw/6OgyvK1OmDHfddZfXjud3Vz1FR8fTqtWXREc7+i0feqger7/ehmuusfshjPe5ugzVGE/wxHCC3yWKChWKUL16ccqVK8TUqR1o1epaX4dk8qnQ0FCOHz9OqVKlLFkYr1DnehShoaE5Wm+eTxSxsYm89NKvPPlkY2rVKomI8M03d1CiRKjNy2R8Kjw8nOjo6BxfG8AYV/5e4S4n5dlEkZqqzJy5heefX8GxYwlERsaycGEPAEqXLuTj6IyB4ODgHF1lzBhf8ehXbhHpIiK7RCRKRC65G0VEQkTka+fza0Wksjv1/vbbIVq2/IJHH13EsWMJ3HRTOK+/flNOh2+MMQYPtihEJBCYDnQCooF1IrJAVbenK9YfiFXV6iLSG3gT6HVpbRfs23eK66//AoBrry3ChAk307t3besDNsYYD/Fki6IFEKWqe1X1PDAH6JahTDdgtvPxt0AHyeYT/8SJBIKDAxg5sgW7dj3MfffVsSRhjDEe5LE7s0WkJ9BFVR9xbj8IXK+qA9OV2eosE+3c3uMscyxDXQOAAc7N+sBWjwSd95QGjmVbKn+wc3GBnYsL7FxcUEtVw7IvdilPDmZn9jU/Y1ZypwyqOgOYASAi66/0NnR/Y+fiAjsXF9i5uMDOxQUicnlzH6Xjya6naKBiuu1wIOPk6WllRCQIKAac8GBMxhhjLpMnE8U6oIaIVBGRAkBvYEGGMguAvs7HPYGfNa/NUmiMMX7OY11PqposIgOBH4FAYKaqbhORsTjWbl0AfAx8JiJROFoSvd2oeoanYs6D7FxcYOfiAjsXF9i5uOCKz0Wem2bcGGOMd9kcF8YYY1yyRGGMMcalXJsoPDX9R17kxrkYJiLbRWSziCwRkUq+iNMbsjsX6cr1FBEVEb+9NNKdcyEi9zp/N7aJyJfejtFb3PgbuU5ElorIRuffyW2+iNPTRGSmiBx13qOW2fMiIlOc52mziDR1q2JVzXU/OAa/9wBVgQLAH0DdDGWeBN53Pu4NfO3ruH14LtoBhZyPn8jP58JZLgxYDqwBInwdtw9/L2oAG4ESzu2yvo7bh+diBvCE83FdYJ+v4/bQuWgDNAW2ZvH8bcAPOO5hawmsdafe3Nqi8Mj0H3lUtudCVZeq6lnn5hoc96z4I3d+LwDGAeOBRG8G52XunItHgemqGgugqke9HKO3uHMuFCjqfFyMS+/p8guquhzX96J1Az5VhzVAcREpn129uTVRVAAOpNuOdu7LtIyqJgNxQCmvROdd7pyL9Prj+Mbgj7I9FyLSBKioqt97MzAfcOf3oiZQU0RWicgaEenitei8y51z8RLwgIhEAwuBQd4JLde53M8TIPeuR5Fj03/4Abffp4g8AEQAN3s0It9xeS5EJACYBDzkrYB8yJ3fiyAc3U9tcbQyV4hIfVU96eHYvM2dc3EfMEtV3xaRVjju36qvqqmeDy9XuaLPzdzaorDpPy5w51wgIh2BF4A7VfWcl2LztuzORRiOSSOXicg+HH2wC/x0QNvdv5H5qpqkqn8Cu3AkDn/jzrnoD/wTQFVXA6E4JgzMb9z6PMkotyYKm/7jgmzPhbO75QMcScJf+6Ehm3OhqnGqWlpVK6tqZRzjNXeq6hVPhpaLufM3Mg/HhQ6ISGkcXVF7vRqld7hzLvYDHQBEpA6ORJEf16hdAPyf8+qnlkCcqh7K7kW5sutJPTf9R57j5rl4CygCfOMcz9+vqnf6LGgPcfNc5Atunosfgc4ish1IAZ5R1eO+i9oz3DwXw4EPRWQojq6Wh/zxi6WIfIWjq7G0czzmH0AwgKq+j2N85jYgCjgL9HOrXj88V8YYY3JQbu16MsYYk0tYojDGGOOSJQpjjDEuWaIwxhjjkiUKY4wxLlmiMLmOiKSIyKZ0P5VdlK2c1UyZl3nMZc7ZR/9wTnlR6wrqeFxE/s/5+CERuTbdcx+JSN0cjnOdiDR24zVDRKTQ1R7b5F+WKExulKCqjdP97PPSce9X1UY4Jpt863JfrKrvq+qnzs2HgGvTPfeIqm7PkSgvxPku7sU5BLBEYa6YJQqTJzhbDitE5Hfnzw2ZlKknIr85WyGbRaSGc/8D6fZ/ICKB2RxuOVDd+doOzjUMtjjn+g9x7n9DLqwBMsG57yURGSEiPXHMufWF85gFnS2BCBF5QkTGp4v5IRGZeoVxribdhG4i8p6IrBfH2hMvO/cNxpGwlorIUue+ziKy2nkevxGRItkcx+RzlihMblQwXbfTXOe+o0AnVW0K9AKmZPK6x4F3VLUxjg/qaOd0Db2A1s79KcD92Rz/DmCLiIQCs4BeqtoAx0wGT4hISaA7UE9VGwKvpH+xqn4LrMfxzb+xqiake/pb4O50272Ar68wzi44pun42wuqGgE0BG4WkYaqOgXHXD7tVLWdcyqP0UBH57lcDwzL5jgmn8uVU3iYfC/B+WGZXjAwzdknn4Jj3qKMVgMviEg48G9VjRSRDkAzYJ1zepOCOJJOZr4QkQRgH45pqGsBf6rqbufzs4GngGk41rr4SET+A7g9pbmqxojIXuc8O5HOY6xy1ns5cRbGMV1F+hXK7hWRATj+rsvjWKBnc4bXtnTuX+U8TgEc582YLFmiMHnFUOAI0AhHS/iSRYlU9UsRWQvcDvwoIo/gmFZ5tqo+78Yx7k8/gaCIZLq+iXNuoRY4JpnrDQwE2l/Ge/kauBfYCcxVVRXHp7bbceJYxe0NYDpwt4hUAUYAzVU1VkRm4Zj4LiMBflLV+y4jXpPPWdeTySuKAYec6wc8iOPb9EVEpCqw19ndsgBHF8wSoKeIlHWWKSnurym+E6gsItWd2w8Cvzj79Iup6kIcA8WZXXkUj2Pa88z8G7gLxxoJXzv3XVacqpqEowuppbPbqihwBogTkXLArVnEsgZo/fd7EpFCIpJZ68yYNJYoTF7xLtBXRNbg6HY6k0mZXsBWEdkE1Max5ON2HB+oi0RkM/ATjm6ZbKlqIo7ZNb8RkS1AKvA+jg/d7531/YKjtZPRLOD9vwezM9QbC2wHKqnqb859lx2nc+zjbWCEqv6BY33sbcBMHN1Zf5sB/CAiS1U1BscVWV85j7MGx7kyJks2e6wxxhiXrEVhjDHGJUsUxhhjXLJEYYwxxiVLFMYYY1yyRGGMMcYlSxTGGGNcskRhjDHGpf8HHXvMNN+3Q9YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = log_reg()\n",
    "regressor = regressor.fit(train_X,train_y)\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "area_uc=0\n",
    "acc=0\n",
    "for y in test_y.tolist():\n",
    "    if y=='bending':\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(0)\n",
    "for p in regressor.predict(test_X).tolist():\n",
    "    if p=='bending':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)    \n",
    "        \n",
    "cm = metrics.confusion_matrix(y_true,y_pred)\n",
    "print(\"\\nConfusion Matrix for Test data:\\n\",cm)\n",
    "acc=regressor.score(test_X,test_y)\n",
    "fpr, tpr, _ = roc_curve(y_true,y_pred)\n",
    "area_uc = auc(fpr, tpr)\n",
    "\n",
    "print(\"\\nArea under curve for Test data:\\n\",area_uc)\n",
    "print(\"\\nAccuracy:\\n\",acc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red',lw=2, label='ROC curve (area = %0.2f)' % area_uc)\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.10])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "Both the test and cross-validation accuracy are 1.0. <br> <br>\n",
    "Both model are working well. But since the minority class is less , both models can still be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are not well separated. That is why when we cross validate using KFold ,we get errors as some classes get no samples at all.<br> <br>\n",
    "To alleviate this,\n",
    "I used the Stratified K-fold cross validation which takes care of the class imbalance. In bending and Non-bending , the majority class is Non-bending, due to this if the test set gets 1 out of 10 sample as bending, it will be classified as non-bending.But the accuracy and AUC will still be high. <br><br>\n",
    "By shuffling the dataset and using Stratified K-fold I reduced the instability of logistic regression parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a logistic regression model based on case-control sampling and adjusting its parameters to deal with class-imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Test data:\n",
      " [[15  0]\n",
      " [ 0  4]]\n",
      "\n",
      "Area under curve for Test data:\n",
      " 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = log_reg(class_weight='balanced')\n",
    "regressor = regressor.fit(train_X,train_y)\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "area_uc=0\n",
    "for y in test_y.tolist():\n",
    "    if y=='bending':\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(0)\n",
    "for p in regressor.predict(test_X).tolist():\n",
    "    if p=='bending':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)    \n",
    "        \n",
    "cm = metrics.confusion_matrix(y_true,y_pred)\n",
    "print(\"\\nConfusion Matrix for Test data:\\n\",cm)\n",
    "fpr, tpr, _ = roc_curve(y_true,y_pred)\n",
    "area_uc = auc(fpr, tpr)\n",
    "print(\"\\nArea under curve for Test data:\\n\",area_uc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red',lw=2, label='ROC curve (area = %0.2f)' % area_uc)\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.10])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Using L1-penalized logistic regression\n",
    "#### Here, we are cross-validating to get both the value of l and C- the penatly parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Best L for L1-penalized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "area_uc_all=[]\n",
    "pen_weight_all=[]\n",
    "acc_all=[]\n",
    "from sklearn.linear_model import LogisticRegressionCV as log_regcv\n",
    "from sklearn import preprocessing\n",
    "mean_auc={}\n",
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "for l in range(1,21):\n",
    "    new_dict={}\n",
    "    area_uc = []\n",
    "    pen_weight=[]\n",
    "    for f in features:\n",
    "        for e in imp_extract:\n",
    "            new_dict[e+\"_\"+f] = []\n",
    "    new_dict['activity'] = []\n",
    "\n",
    "    for activity in activities:\n",
    "        mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "        for fname in os.listdir(mypath):\n",
    "            df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "            #print(df)\n",
    "            df_split=np.array_split(df,l)\n",
    "            #print(df_split)\n",
    "            for splits in df_split:\n",
    "                for f in features:\n",
    "                    new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                    new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                    new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "                if activity=='bending1' or activity=='bending2':\n",
    "                    new_dict['activity'].append('bending')\n",
    "                else:\n",
    "                    new_dict['activity'].append('not-bending')\n",
    "\n",
    "    new_train=pd.DataFrame(new_dict)\n",
    "    data_X=new_train.loc[:,new_train.columns!='activity']\n",
    "    data_y=new_train['activity']\n",
    "    acc=[]\n",
    "    \n",
    "    norm1=preprocessing.MinMaxScaler()\n",
    "    norm=norm1.fit_transform(data_X.values)\n",
    "    data_X=pd.DataFrame(norm,columns=data_X.columns)\n",
    "\n",
    "    st_kfcv = StratifiedKFold(n_splits=5,shuffle=False)\n",
    " \n",
    "    for train_index,val_index in st_kfcv.split(data_X,data_y):\n",
    "        X_train, X_val = data_X.iloc[train_index.tolist(),:], data_X.iloc[val_index.tolist(),:]\n",
    "        y_train, y_val = data_y[train_index.tolist()], data_y[val_index.tolist()]\n",
    "    \n",
    "            \n",
    "        regressor = log_regcv(Cs=10,penalty='l1',solver='liblinear')\n",
    "        regressor = regressor.fit(X_train, y_train)\n",
    "        y_true=[]\n",
    "        y_pred=[]\n",
    "        for y in y_val.tolist():\n",
    "            if y=='bending':\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "        for p in regressor.predict(X_val).tolist():\n",
    "            if p=='bending':\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_true,y_pred)\n",
    "        area_uc.append(auc(fpr, tpr))\n",
    "        acc.append(regressor.score(X_val,y_val))\n",
    "        pen_weight.append(regressor.C_)\n",
    "    area_uc_all.append(area_uc)\n",
    "    pen_weight_all.append(pen_weight)\n",
    "    acc_all.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_values=[]\n",
    "op_lam=[]\n",
    "auc_pen=[]\n",
    "acc_1=[]\n",
    "for l in range(1,21):\n",
    "    for i in range(1,6):\n",
    "        l_values.append(l)\n",
    "        auc_pen.append(area_uc_all[l-1][i-1])\n",
    "        op_lam.append(float(pen_weight_all[l-1][i-1]))\n",
    "        acc_1.append(acc_all[l-1][i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>Optimal lambda</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.927273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.890909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.927536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.942029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.927536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>0.721591</td>\n",
       "      <td>0.650602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.927711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.937198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.643519</td>\n",
       "      <td>0.763285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>15</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.932367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>16</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.806753</td>\n",
       "      <td>0.918552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>16</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.617367</td>\n",
       "      <td>0.742081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>16</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.936652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.913636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>17</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>17</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.824004</td>\n",
       "      <td>0.931915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>17</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.677577</td>\n",
       "      <td>0.748936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>17</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>17</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.914530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.817130</td>\n",
       "      <td>0.927711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.653935</td>\n",
       "      <td>0.721774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>18</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.955645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>18</td>\n",
       "      <td>21.544347</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.923387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>19</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>19</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.825077</td>\n",
       "      <td>0.935115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>19</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.623452</td>\n",
       "      <td>0.736641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>19</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.938931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>19</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.908397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20</td>\n",
       "      <td>1291.549665</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.996377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.728261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.938406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L  Optimal lambda       AUC  Accuracy\n",
       "0    1        2.782559  1.000000  1.000000\n",
       "1    1        2.782559  0.750000  0.928571\n",
       "2    1       21.544347  0.916667  0.857143\n",
       "3    1        2.782559  0.750000  0.928571\n",
       "4    1       21.544347  1.000000  1.000000\n",
       "5    2    10000.000000  1.000000  1.000000\n",
       "6    2      166.810054  0.750000  0.928571\n",
       "7    2       21.544347  0.770833  0.785714\n",
       "8    2     1291.549665  1.000000  1.000000\n",
       "9    2      166.810054  0.666667  0.925926\n",
       "10   3        0.046416  0.500000  0.857143\n",
       "11   3       21.544347  0.694444  0.833333\n",
       "12   3        2.782559  0.716667  0.804878\n",
       "13   3        2.782559  0.600000  0.902439\n",
       "14   3        2.782559  0.700000  0.926829\n",
       "15   4        0.046416  0.500000  0.857143\n",
       "16   4       21.544347  0.836310  0.927273\n",
       "17   4       21.544347  0.782738  0.727273\n",
       "18   4        2.782559  0.571429  0.890909\n",
       "19   4        2.782559  0.642857  0.909091\n",
       "20   5     1291.549665  0.958333  0.927536\n",
       "21   5        2.782559  0.872222  0.942029\n",
       "22   5        2.782559  0.733333  0.782609\n",
       "23   5        2.782559  0.666667  0.913043\n",
       "24   5      166.810054  0.722222  0.927536\n",
       "25   6        2.782559  1.000000  1.000000\n",
       "26   6        2.782559  0.849747  0.939759\n",
       "27   6     1291.549665  0.721591  0.650602\n",
       "28   6        2.782559  0.727273  0.927711\n",
       "29   6      166.810054  0.650000  0.914634\n",
       "..  ..             ...       ...       ...\n",
       "70  15        2.782559  1.000000  1.000000\n",
       "71  15        2.782559  0.822222  0.937198\n",
       "72  15        2.782559  0.643519  0.763285\n",
       "73  15        2.782559  0.740741  0.932367\n",
       "74  15        2.782559  0.666667  0.913043\n",
       "75  16     1291.549665  1.000000  1.000000\n",
       "76  16        2.782559  0.806753  0.918552\n",
       "77  16        2.782559  0.617367  0.742081\n",
       "78  16        2.782559  0.758621  0.936652\n",
       "79  16        2.782559  0.660714  0.913636\n",
       "80  17        2.782559  1.000000  1.000000\n",
       "81  17        2.782559  0.824004  0.931915\n",
       "82  17        2.782559  0.677577  0.748936\n",
       "83  17        2.782559  0.750000  0.935897\n",
       "84  17     1291.549665  0.666667  0.914530\n",
       "85  18        2.782559  1.000000  1.000000\n",
       "86  18       21.544347  0.817130  0.927711\n",
       "87  18        2.782559  0.653935  0.721774\n",
       "88  18       21.544347  0.828125  0.955645\n",
       "89  18       21.544347  0.703125  0.923387\n",
       "90  19        2.782559  1.000000  1.000000\n",
       "91  19        2.782559  0.825077  0.935115\n",
       "92  19        2.782559  0.623452  0.736641\n",
       "93  19        2.782559  0.764706  0.938931\n",
       "94  19        2.782559  0.647059  0.908397\n",
       "95  20     1291.549665  0.997917  0.996377\n",
       "96  20    10000.000000  0.844444  0.934783\n",
       "97  20        2.782559  0.631250  0.728261\n",
       "98  20        2.782559  0.763889  0.938406\n",
       "99  20        2.782559  0.625000  0.902174\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_values = pd.DataFrame({\"L\":l_values,\"Optimal lambda\":op_lam,\"AUC\":auc_pen,\"Accuracy\":acc_1})\n",
    "coef_values[['L','Optimal lambda','AUC',\"Accuracy\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best L for L-1 penalized is 1 with penalty=21.544347"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test set for L1 penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/test\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_test=pd.DataFrame(new_dict)\n",
    "\n",
    "\n",
    "test_X=new_test.loc[:,new_test.columns!='activity']\n",
    "\n",
    "test_y=new_test['activity']\n",
    "X_train = new_train.loc[:,new_train.columns!='activity']\n",
    "y_train = new_train['activity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating p-values for L1-penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.677699e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.689662e-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.629374e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.005191e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.347296e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.479159e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.028859e-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.351342e-198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.060903e-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        P-values\n",
       "0   3.677699e-03\n",
       "1   1.689662e-71\n",
       "2   4.629374e-35\n",
       "3   2.005191e-12\n",
       "4   1.347296e-16\n",
       "5   2.479159e-21\n",
       "6  5.028859e-127\n",
       "7  7.351342e-198\n",
       "8   1.060903e-40"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,p=chi2(X_train[best_features],y_train)\n",
    "coef_values = pd.DataFrame({\"P-values\":p})\n",
    "coef_values[['P-values']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using L1 Penalty=21.544347 with L=1 on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for the test set: \n",
      "[[15  0]\n",
      " [ 0  4]]\n",
      "\n",
      "AUC : 1.0\n"
     ]
    }
   ],
   "source": [
    "regressor1 = log_reg(penalty='l1',solver='liblinear',C=21.544347)\n",
    "regressor1 = regressor1.fit(X_train, y_train)\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "for y in test_y.tolist():\n",
    "    if y=='bending':\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(0)\n",
    "y_pred1=regressor1.predict(test_X).tolist()\n",
    "for y in y_pred1:\n",
    "    if y=='bending':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "cm = metrics.confusion_matrix(y_true,y_pred)\n",
    "print(\"Confusion Matrix for the test set: \")\n",
    "print(cm)\n",
    "fpr, tpr, _ = roc_curve(y_true,y_pred)\n",
    "print(\"\\nAUC :\",auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of  L1-penalized with variable selection using p-values. Which one performs better? Which one is easier to implement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L-1 penalized model is easier to program and implement as we have to add just one regularization term to be added. <br><br>\n",
    "The Area-under the curve for both the models on the test set is 1. From the p-values we can make out that L-1 penalized model performs much better than the model with backward variable selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification (The Realistic Case)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/test\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            if activity=='bending1' or activity=='bending2':\n",
    "                new_dict['activity'].append('bending')\n",
    "            else:\n",
    "                new_dict['activity'].append('not-bending')\n",
    "            \n",
    "new_test=pd.DataFrame(new_dict)\n",
    "\n",
    "\n",
    "test_X=new_test.loc[:,new_test.columns!='activity']\n",
    "\n",
    "test_y=new_test['activity']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an L1-penalized multinomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "d={}\n",
    "area_uc_all=[]\n",
    "pen_weight_all=[]\n",
    "acc_all=[]\n",
    "auc1_all=[]\n",
    "from sklearn.linear_model import LogisticRegressionCV as log_regcv\n",
    "from sklearn import preprocessing\n",
    "mean_auc={}\n",
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "activities=[\"bending1\",\"bending2\",\"cycling\",\"lying\",\"sitting\",\"standing\",\"walking\"]\n",
    "\n",
    "for l in range(1,21):\n",
    "    new_dict={}\n",
    "    area_uc = []\n",
    "    pen_weight=[]\n",
    "    for f in features:\n",
    "        for e in imp_extract:\n",
    "            new_dict[e+\"_\"+f] = []\n",
    "    new_dict['activity'] = []\n",
    "\n",
    "    for activity in activities:\n",
    "        mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "        for fname in os.listdir(mypath):\n",
    "            df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "            #print(df)\n",
    "            df_split=np.array_split(df,l)\n",
    "            #print(df_split)\n",
    "            for splits in df_split:\n",
    "                for f in features:\n",
    "                    new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                    new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                    new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "                new_dict['activity'].append((activities.index(activity)+1))\n",
    "               \n",
    "\n",
    "    new_train=pd.DataFrame(new_dict)\n",
    "    #new_train= new_train.sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "    data_X=new_train.loc[:,new_train.columns!='activity']\n",
    "    data_y=new_train['activity']\n",
    "    acc=[]\n",
    "    auc1=[]\n",
    "    \n",
    "    norm1=preprocessing.MinMaxScaler()\n",
    "    norm=norm1.fit_transform(data_X.values)\n",
    "    data_X=pd.DataFrame(norm,columns=data_X.columns)\n",
    "\n",
    "    st_kfcv = StratifiedKFold(n_splits=5,shuffle=False)\n",
    " \n",
    "    for train_index,val_index in st_kfcv.split(data_X,data_y):\n",
    "        X_train, X_val = data_X.iloc[train_index.tolist(),:], data_X.iloc[val_index.tolist(),:]\n",
    "        y_train, y_val = data_y[train_index.tolist()], data_y[val_index.tolist()]\n",
    "    \n",
    "            \n",
    "        regressor = log_regcv(Cs=10,penalty='l1',solver='liblinear')\n",
    "        regressor = regressor.fit(X_train, y_train)\n",
    "     \n",
    "        \n",
    "        y_pred=regressor.predict(X_val)\n",
    "       \n",
    "        #fpr, tpr, _ = roc_curve(y_val,y_pred)\n",
    "        #area_uc.append(auc(fpr, tpr))\n",
    "        acc.append(regressor.score(X_val,y_val))\n",
    "        pen_weight.append(regressor.C_)\n",
    "     \n",
    "        #fpr = dict()\n",
    "        #tpr = dict()\n",
    "        #roc_auc = dict()\n",
    "        #for i in range(0,7):\n",
    "           # fpr[i], tpr[i], _ = roc_curve(y_val[i], y_pred[i])\n",
    "            #roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        #roc_auc=[0 if np.math.isnan(x) else x for x in roc_auc.values()]\n",
    "        #auc1.append(roc_auc)\n",
    "    #area_uc_all.append(area_uc)\n",
    "    pen_weight_all.append(pen_weight)\n",
    "    acc_all.append(max(acc))        \n",
    "   # auc1_all.append(auc1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L=10 , Accuracy for Multinomial Logistic Regression= 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Naive Bayes’ classifier. Use both Gaussian and Multi- nomial priors and comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/test\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            new_dict['activity'].append(activity)\n",
    "            \n",
    "new_test=pd.DataFrame(new_dict)\n",
    "\n",
    "\n",
    "X_test=new_test.loc[:,new_test.columns!='activity']\n",
    "\n",
    "y_test=new_test['activity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "imp_extract=['max','mean','median']\n",
    "new_dict={}\n",
    "for f in features:\n",
    "    for e in imp_extract:\n",
    "        new_dict[e+\"_\"+f] = []\n",
    "new_dict['activity'] = []\n",
    "\n",
    "for activity in activities:\n",
    "    mypath=\"C:/Users/ssaya/Downloads/Machine learning/homework/3/AReM_1/{0}/train\".format(activity)\n",
    "    for fname in os.listdir(mypath):\n",
    "        df=pd.read_csv(mypath+'/'+fname,skiprows=4)\n",
    "        #print(df)\n",
    "        df_split=np.array_split(df,1)\n",
    "        #print(df_split)\n",
    "        for splits in df_split:\n",
    "            for f in features:\n",
    "                new_dict[\"max\"+\"_\"+f].append(np.max(splits[f]))\n",
    "                new_dict[\"mean\"+\"_\"+f].append(np.mean(splits[f]))\n",
    "                new_dict[\"median\"+\"_\"+f].append(np.median(splits[f]))\n",
    "            new_dict['activity'].append(activity)\n",
    "new_train=pd.DataFrame(new_dict)                \n",
    "X_train = new_train.loc[:,new_train.columns!='activity']\n",
    "y_train = new_train['activity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Gaussian Naive Bayes : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "act_no ={'bending1':0,'bending2':1,'cycling':2,'lying':3,'sitting':4,'standing':5,'walking':6}\n",
    "gausnb= GaussianNB() \n",
    "y_pred_gauss=[]\n",
    "y_true_gauss=[]\n",
    "gb=gausnb.fit(X_train, y_train)\n",
    "gb_pred=gb.predict(X_test)\n",
    "for i in list(gb_pred):\n",
    "    y_pred_gauss.append(act_no[i])\n",
    "for i in list(y_test):\n",
    "    y_true_gauss.append(act_no[i])\n",
    "acc=gb.score(X_test,y_test)\n",
    "print(\"\\nAccuracy for Gaussian Naive Bayes :\",acc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true_gauss, y_pred_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Multinomial Naive Bayes : 1.0\n"
     ]
    }
   ],
   "source": [
    "act_no ={'bending1':0,'bending2':1,'cycling':2,'lying':3,'sitting':4,'standing':5,'walking':6}\n",
    "multinb = MultinomialNB() \n",
    "y_pred_multi=[]\n",
    "y_true_multi=[]\n",
    "mnb=multinb.fit(X_train, y_train)\n",
    "mnb_pred=mnb.predict(X_test)\n",
    "for i in list(mnb_pred):\n",
    "    y_pred_multi.append(act_no[i])\n",
    "for i in list(y_test):\n",
    "    y_true_multi.append(act_no[i])\n",
    "    \n",
    "acc=mnb.score(X_test,y_test)\n",
    "print(\"\\nAccuracy for Multinomial Naive Bayes :\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true_multi, y_pred_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which method is better for multi-class classification in this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "##### Accuracy for Multinomial Logistic Regression : 0.94 for L=10\n",
    "##### Accuracy for Gaussian Naive Bayes : 0.9473684210526315\n",
    "##### Accuracy for Multinomial Naive Bayes : 1.0\n",
    "\n",
    "### Inference :\n",
    "##### Multinomial Naive Bayes is better for multi-class classification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
